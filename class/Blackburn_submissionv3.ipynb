{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion MNIST Competition",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackbtccollins/AIML_Training/blob/main/class/Blackburn_submissionv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHwxGemYV_FT"
      },
      "source": [
        "# Fashion MNIST Competition! - Blackburn Submission\n",
        "**Author**: T. Blackburn\n",
        "\n",
        "**Updates**: New Version\n",
        "\n",
        "## Problem\n",
        "\n",
        "Classify images from the \"Fashion MNIST\" data set.   Optimize the test accuracy.\n",
        "\n",
        "## Metrics\n",
        "\n",
        "This competition is evaluated on the mean Dice coefficient. The Dice coefficient can be used to compare the pixel-wise agreement between a predicted segmentation and its corresponding ground truth. The formula is given by:![alt text](https://user-images.githubusercontent.com/26015273/41822460-2ca0a90a-77f0-11e8-9c71-7e88fa6b5c61.gif)\n",
        "\n",
        "\n",
        "The double sum is over the observations `i`, whose number is `N`, and the categories `c`, whose number is `C`. The term `1_{y_i \\in C_c}` is the indicator function of the `i`th observation belonging to the `c`th category. The `p_{model}[y_i \\in C_c]` is the probability predicted by the model for the `i`th observation to belong to the `c`th category. When there are more than two categories, the neural network outputs a vector of `C` probabilities, each giving the probability that the network input should be classified as belonging to the respective category. When the number of categories is just two, the neural network outputs a single probability `\\hat{y}_i`, with the other one being `1` minus the output. This is why the binary cross entropy looks a bit different from categorical cross entropy, despite being a special case of it.\n",
        "\n",
        "## Dataset\n",
        "\n",
        "This dataset is the Fashion MNIST dataset\n",
        "\n",
        "Recently, the researchers at Zalando, an e-commerce company, introduced Fashion MNIST as a drop-in replacement for the original MNIST dataset. Like MNIST, Fashion MNIST consists of a training set consisting of 60,000 examples belonging to 10 different classes and a test set of 10,000 examples. Each training example is a gray-scale image, 28x28 in size. The authors of the work further claim that the Fashion MNIST should actually replace MNIST dataset for benchmarking of new Machine Learning or Computer Vision models.\n",
        "\n",
        "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n",
        "\n",
        "The Labels are:  \n",
        "0 T-shirt/top\n",
        "1 Trouser\n",
        "2 Pullover\n",
        "3 Dress\n",
        "4 Coat\n",
        "5 Sandal\n",
        "6 Shirt\n",
        "7 Sneaker\n",
        "8 Bag\n",
        "9 Ankle boot \n",
        "\n",
        "## Objective\n",
        "\n",
        "In this competition, you can try different variations of the CNN model given as a reference, you may evaluate techniques to squeeze more performance out of a CNN, or you might even try a completely different model, neural network or otherwise.  You will note that there are tips/tricks/techniques documented in many locations on the internet that could be useful.\n",
        "\n",
        "## Rules and Timeline\n",
        "\n",
        "The primary measure for the competition will be the accuracy of prediction on the test data.  Ties will be broken by Precision accuracy first, then Recall Accuracy if needed.\n",
        "\n",
        "The results will be revealed at the end of the last day of class.  Please submit your Metrics blocks (Starts with SUBMIT... and ends with END SUBMISSION) to instructors (wtnewman@raytheon.com) before lunch.\n",
        "\n",
        "A prize will be given to the top finisher(s) based on the judgement of the instructor and the availability of prizes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0A2_Mo0KxWc"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten,  Conv2D, MaxPooling2D, Activation, BatchNormalization\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import TensorBoard,  ModelCheckpoint\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import os\n",
        "%matplotlib inline\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y6VjlzZLKPB"
      },
      "source": [
        "## Set Up Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtL1H333LHGz"
      },
      "source": [
        "epochs = 150                 # Number of Training Epochs\n",
        "num_classes = 10            # This is the number of classes in the Fashion MNIST dataset\n",
        "batch_size = 200          # This parameter can be adjusted\n",
        "img_rows, img_cols = 28, 28 # Pixel sizes of the Images in the Dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SW52B7dT9H5"
      },
      "source": [
        "## Gather and Process Fashion MNIST data\n",
        "\n",
        "1. First, collect the data from Keras (our goal is someday that our organizational data is this easy to get!)\n",
        "2. Then split into train and test sets.\n",
        "3. Next we need to process the data into the proper shape for the CNN\n",
        "4. Then scale the floats to land between 0 and 1.  Often times we use sklearn's MinMaxScaler for this, but in this case we're going for simplicity.\n",
        "5. Next take the y_train and y_test labels and encode them one-hot.  This will enable the CNN to function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZENio2YLPUy",
        "outputId": "2414060b-aa0f-4ba5-f360-b6bca18a4bb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Grab the data from the keras repository\n",
        "\n",
        "mnist_data = fashion_mnist.load_data()\n",
        "x = mnist_data[0][0]\n",
        "y = mnist_data[0][1]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=41)\n",
        "\n",
        "# Process the date into the right tensor shape.  This is a good practice, but\n",
        "# usually tensorflow uses channels last (the 'else' here)\n",
        "\n",
        "if K.image_data_format() == \"channels first\":\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "    \n",
        "#\n",
        "#  Cast to a 32 bit float and then scale so the value is a float between 0 and 1\n",
        "    \n",
        "x_train = x_train.astype(\"float32\")\n",
        "x_test = x_test.astype(\"float32\")\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "#\n",
        "# Convert Class Vector to Binary Class Matrices (one-hot encoding).\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(y_test.shape)\n",
        "\n",
        "#\n",
        "# Function to decode one-hot encoding later on when we want to evaluate performance.\n",
        "def decode_one_hot(y):\n",
        "    y_classes = [np.argmax(yi, axis=None, out=None) for yi in y]\n",
        "    return y_classes\n",
        "\n",
        "'''\n",
        "\n",
        "Below we're experimenting with the Keras ImageDataGenerator.  From my experience, if these parameters\n",
        "are set too aggressively, the loss/accuracy will either never improve or it will take too long to improve.\n",
        "Below is an example of a complex data augmentation regime.  This is just for reference.  See my more simple\n",
        "one at the bottom.\n",
        "\n",
        "    \n",
        "datagen = ImageDataGenerator(rotation_range=0.5, \n",
        "                                 zoom_range=0.1,\n",
        "                                 featurewise_center=True,\n",
        "                                 #featurewise_std_normalization=True,\n",
        "                                 width_shift_range=0.1, \n",
        "                                 height_shift_range=0.1, \n",
        "                                 shear_range=0.1,\n",
        "                                 horizontal_flip=True, \n",
        "                                 fill_mode=\"nearest\")\n",
        "'''\n",
        "#\n",
        "#  Set up our Image Augmentation Data Generator\n",
        "#\n",
        "datagen = ImageDataGenerator(rotation_range=5)\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "(12000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FcFnUPDLvnO"
      },
      "source": [
        "## Build the Model\n",
        "\n",
        "* In this example, we define the below block as a Sequential Model. \n",
        "* See the excellent [Keras Documentation](https://keras.io/guides/sequential_model/) on Sequential Models for info.\n",
        "* Many of these parameters can be experimented with.  The documentation will help you understand how much to experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EWdo8mALXB9",
        "outputId": "9d1b60bb-0398-4610-a0e6-898eb1e8487e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# This is what is known as a Tensorflow (Keras) Sequential model\n",
        "# We will talk at some level about each of these layer types in class.\n",
        "#\n",
        "\n",
        "###Best####\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 #kernel_initializer='he_normal',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, kernel_size=(3,3)))\n",
        "model.add(LeakyReLU(alpha=0.05))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(800))  \n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "my_callbacks = [ModelCheckpoint('model_out.hdf5', monitor='val_accuracy',  mode='max', save_best_only=True, period=1)]\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# This is what is known as a Tensorflow (Keras) Sequential model\n",
        "# We will talk at some level about each of these layer types in class.\n",
        "#\n",
        "\n",
        "###BEST - Save ####\n",
        "\n",
        "#model = Sequential()\n",
        "#\n",
        "#model.add(Conv2D(32, kernel_size=(3,3), input_shape=input_shape))\n",
        "#model.add(Dropout(0.3))\n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Conv2D(64, kernel_size=(3,3)))\n",
        "#model.add(LeakyReLU(alpha=0.05))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(100))  \n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "#model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "#\n",
        "#my_callbacks = [ModelCheckpoint('model_out.hdf5', monitor='acc', save_best_only=True, period=1)]"
      ],
      "metadata": {
        "id": "BUyaq5L-Q1Di"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvIfjap-L8TO"
      },
      "source": [
        "## Fit and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5U20dV1L-eP",
        "outputId": "a9f6ce05-5e22-4038-9289-b20bbf5728fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Flag to determine whether we use Keras' Image augmentation data generator\n",
        "augmentation = False\n",
        "\n",
        "#\n",
        "# Compile the model so we can fit it. Researching loss functions and optimizers\n",
        "# might be a good thing to do.\n",
        "#\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, \n",
        "              optimizer=keras.optimizers.Adam(), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "if not augmentation:\n",
        "    #\n",
        "    # Fit the model.  Once the model is trained we'll evaluate the performance.\n",
        "    print('not using image augmentation')\n",
        "    hist = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=my_callbacks)\n",
        "else:\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "    hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                           steps_per_epoch=len(x_train) / batch_size, validation_data=(x_test, y_test),\n",
        "                           epochs=epochs, verbose=1, callbacks=my_callbacks, workers = 2)\n",
        "\n",
        "\n",
        "score = model.evaluate(x_test, y_test)\n",
        "\n",
        "#\n",
        "# Predict on the test data and pass to metrics function\n",
        "yhat = np.argmax(model.predict(x_test), axis=-1)\n",
        "y_dec = decode_one_hot(y_test)\n",
        "\n",
        "print(\"\\nSUBMIT THIS BLOCK for the Competition\\n\")\n",
        "print(metrics.classification_report(y_dec, yhat))\n",
        "print(\"Testing Loss:\", score[0])\n",
        "print(\"Testing Accuracy:\", score[1])\n",
        "print(\"END SUBMISSION BLOCK\\n\")\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not using image augmentation\n",
            "Epoch 1/150\n",
            "240/240 [==============================] - 16s 20ms/step - loss: 0.6637 - accuracy: 0.7615 - val_loss: 0.5464 - val_accuracy: 0.8398\n",
            "Epoch 2/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.4163 - accuracy: 0.8492 - val_loss: 0.4154 - val_accuracy: 0.8713\n",
            "Epoch 3/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.3642 - accuracy: 0.8682 - val_loss: 0.3803 - val_accuracy: 0.8821\n",
            "Epoch 4/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.3291 - accuracy: 0.8795 - val_loss: 0.3414 - val_accuracy: 0.8940\n",
            "Epoch 5/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.3095 - accuracy: 0.8875 - val_loss: 0.3200 - val_accuracy: 0.9011\n",
            "Epoch 6/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.2867 - accuracy: 0.8945 - val_loss: 0.3024 - val_accuracy: 0.9041\n",
            "Epoch 7/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.2722 - accuracy: 0.8986 - val_loss: 0.2718 - val_accuracy: 0.9094\n",
            "Epoch 8/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.2579 - accuracy: 0.9038 - val_loss: 0.2742 - val_accuracy: 0.9128\n",
            "Epoch 9/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.2460 - accuracy: 0.9072 - val_loss: 0.2718 - val_accuracy: 0.9095\n",
            "Epoch 10/150\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.2353 - accuracy: 0.9118 - val_loss: 0.2467 - val_accuracy: 0.9158\n",
            "Epoch 11/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.2266 - accuracy: 0.9163 - val_loss: 0.2413 - val_accuracy: 0.9204\n",
            "Epoch 12/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.2166 - accuracy: 0.9187 - val_loss: 0.2501 - val_accuracy: 0.9174\n",
            "Epoch 13/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.2104 - accuracy: 0.9213 - val_loss: 0.2322 - val_accuracy: 0.9224\n",
            "Epoch 14/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.2011 - accuracy: 0.9236 - val_loss: 0.2378 - val_accuracy: 0.9224\n",
            "Epoch 15/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.1956 - accuracy: 0.9254 - val_loss: 0.2304 - val_accuracy: 0.9190\n",
            "Epoch 16/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.1959 - accuracy: 0.9261 - val_loss: 0.2217 - val_accuracy: 0.9234\n",
            "Epoch 17/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1829 - accuracy: 0.9309 - val_loss: 0.2205 - val_accuracy: 0.9248\n",
            "Epoch 18/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1795 - accuracy: 0.9324 - val_loss: 0.2098 - val_accuracy: 0.9280\n",
            "Epoch 19/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.1740 - accuracy: 0.9344 - val_loss: 0.2128 - val_accuracy: 0.9280\n",
            "Epoch 20/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.1701 - accuracy: 0.9359 - val_loss: 0.2111 - val_accuracy: 0.9282\n",
            "Epoch 21/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.1646 - accuracy: 0.9373 - val_loss: 0.2148 - val_accuracy: 0.9231\n",
            "Epoch 22/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1638 - accuracy: 0.9387 - val_loss: 0.2043 - val_accuracy: 0.9283\n",
            "Epoch 23/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.1566 - accuracy: 0.9419 - val_loss: 0.2061 - val_accuracy: 0.9271\n",
            "Epoch 24/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.1511 - accuracy: 0.9425 - val_loss: 0.2023 - val_accuracy: 0.9270\n",
            "Epoch 25/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1483 - accuracy: 0.9446 - val_loss: 0.2063 - val_accuracy: 0.9259\n",
            "Epoch 26/150\n",
            "240/240 [==============================] - 5s 21ms/step - loss: 0.1460 - accuracy: 0.9443 - val_loss: 0.1978 - val_accuracy: 0.9296\n",
            "Epoch 27/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.1379 - accuracy: 0.9468 - val_loss: 0.2001 - val_accuracy: 0.9303\n",
            "Epoch 28/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.1381 - accuracy: 0.9474 - val_loss: 0.1995 - val_accuracy: 0.9301\n",
            "Epoch 29/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.1357 - accuracy: 0.9486 - val_loss: 0.1975 - val_accuracy: 0.9309\n",
            "Epoch 30/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.1332 - accuracy: 0.9496 - val_loss: 0.1915 - val_accuracy: 0.9320\n",
            "Epoch 31/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.1298 - accuracy: 0.9496 - val_loss: 0.1921 - val_accuracy: 0.9312\n",
            "Epoch 32/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.1282 - accuracy: 0.9513 - val_loss: 0.1983 - val_accuracy: 0.9290\n",
            "Epoch 33/150\n",
            "240/240 [==============================] - 6s 23ms/step - loss: 0.1293 - accuracy: 0.9512 - val_loss: 0.1934 - val_accuracy: 0.9317\n",
            "Epoch 34/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1242 - accuracy: 0.9520 - val_loss: 0.1971 - val_accuracy: 0.9293\n",
            "Epoch 35/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1245 - accuracy: 0.9540 - val_loss: 0.1925 - val_accuracy: 0.9305\n",
            "Epoch 36/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.1224 - accuracy: 0.9533 - val_loss: 0.1948 - val_accuracy: 0.9307\n",
            "Epoch 37/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.1185 - accuracy: 0.9557 - val_loss: 0.1952 - val_accuracy: 0.9301\n",
            "Epoch 38/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1152 - accuracy: 0.9561 - val_loss: 0.1943 - val_accuracy: 0.9325\n",
            "Epoch 39/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.1104 - accuracy: 0.9581 - val_loss: 0.1898 - val_accuracy: 0.9317\n",
            "Epoch 40/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.1130 - accuracy: 0.9572 - val_loss: 0.1969 - val_accuracy: 0.9301\n",
            "Epoch 41/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.1091 - accuracy: 0.9587 - val_loss: 0.2040 - val_accuracy: 0.9287\n",
            "Epoch 42/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.1081 - accuracy: 0.9589 - val_loss: 0.1973 - val_accuracy: 0.9308\n",
            "Epoch 43/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.1070 - accuracy: 0.9589 - val_loss: 0.1950 - val_accuracy: 0.9294\n",
            "Epoch 44/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.1059 - accuracy: 0.9607 - val_loss: 0.1920 - val_accuracy: 0.9312\n",
            "Epoch 45/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1062 - accuracy: 0.9602 - val_loss: 0.1940 - val_accuracy: 0.9298\n",
            "Epoch 46/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.1026 - accuracy: 0.9601 - val_loss: 0.1935 - val_accuracy: 0.9331\n",
            "Epoch 47/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0998 - accuracy: 0.9629 - val_loss: 0.1943 - val_accuracy: 0.9323\n",
            "Epoch 48/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.0993 - accuracy: 0.9629 - val_loss: 0.1905 - val_accuracy: 0.9317\n",
            "Epoch 49/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.0970 - accuracy: 0.9629 - val_loss: 0.1999 - val_accuracy: 0.9322\n",
            "Epoch 50/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.0996 - accuracy: 0.9622 - val_loss: 0.1994 - val_accuracy: 0.9310\n",
            "Epoch 51/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0966 - accuracy: 0.9630 - val_loss: 0.1944 - val_accuracy: 0.9311\n",
            "Epoch 52/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.0980 - accuracy: 0.9632 - val_loss: 0.1968 - val_accuracy: 0.9327\n",
            "Epoch 53/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0961 - accuracy: 0.9639 - val_loss: 0.2023 - val_accuracy: 0.9310\n",
            "Epoch 54/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.0934 - accuracy: 0.9643 - val_loss: 0.1945 - val_accuracy: 0.9320\n",
            "Epoch 55/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.0907 - accuracy: 0.9658 - val_loss: 0.1918 - val_accuracy: 0.9332\n",
            "Epoch 56/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0916 - accuracy: 0.9653 - val_loss: 0.1982 - val_accuracy: 0.9329\n",
            "Epoch 57/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.0916 - accuracy: 0.9652 - val_loss: 0.1948 - val_accuracy: 0.9334\n",
            "Epoch 58/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.0916 - accuracy: 0.9657 - val_loss: 0.1987 - val_accuracy: 0.9326\n",
            "Epoch 59/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0901 - accuracy: 0.9666 - val_loss: 0.1961 - val_accuracy: 0.9333\n",
            "Epoch 60/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.0905 - accuracy: 0.9662 - val_loss: 0.1968 - val_accuracy: 0.9329\n",
            "Epoch 61/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0899 - accuracy: 0.9672 - val_loss: 0.2050 - val_accuracy: 0.9337\n",
            "Epoch 62/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.0882 - accuracy: 0.9674 - val_loss: 0.1951 - val_accuracy: 0.9330\n",
            "Epoch 63/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.0817 - accuracy: 0.9692 - val_loss: 0.2017 - val_accuracy: 0.9336\n",
            "Epoch 64/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0856 - accuracy: 0.9685 - val_loss: 0.2048 - val_accuracy: 0.9317\n",
            "Epoch 65/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.0844 - accuracy: 0.9683 - val_loss: 0.1988 - val_accuracy: 0.9331\n",
            "Epoch 66/150\n",
            "240/240 [==============================] - 5s 21ms/step - loss: 0.0859 - accuracy: 0.9690 - val_loss: 0.1989 - val_accuracy: 0.9350\n",
            "Epoch 67/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.0815 - accuracy: 0.9698 - val_loss: 0.2004 - val_accuracy: 0.9333\n",
            "Epoch 68/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.0846 - accuracy: 0.9675 - val_loss: 0.1927 - val_accuracy: 0.9353\n",
            "Epoch 69/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0830 - accuracy: 0.9680 - val_loss: 0.2052 - val_accuracy: 0.9335\n",
            "Epoch 70/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.0804 - accuracy: 0.9706 - val_loss: 0.2023 - val_accuracy: 0.9360\n",
            "Epoch 71/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0835 - accuracy: 0.9685 - val_loss: 0.2051 - val_accuracy: 0.9340\n",
            "Epoch 72/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0831 - accuracy: 0.9691 - val_loss: 0.2070 - val_accuracy: 0.9329\n",
            "Epoch 73/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0842 - accuracy: 0.9696 - val_loss: 0.2104 - val_accuracy: 0.9286\n",
            "Epoch 74/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0777 - accuracy: 0.9717 - val_loss: 0.2023 - val_accuracy: 0.9338\n",
            "Epoch 75/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0778 - accuracy: 0.9710 - val_loss: 0.2054 - val_accuracy: 0.9348\n",
            "Epoch 76/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0745 - accuracy: 0.9719 - val_loss: 0.2068 - val_accuracy: 0.9358\n",
            "Epoch 77/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0767 - accuracy: 0.9711 - val_loss: 0.2054 - val_accuracy: 0.9342\n",
            "Epoch 78/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.0784 - accuracy: 0.9713 - val_loss: 0.2063 - val_accuracy: 0.9337\n",
            "Epoch 79/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0740 - accuracy: 0.9725 - val_loss: 0.2047 - val_accuracy: 0.9350\n",
            "Epoch 80/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0782 - accuracy: 0.9707 - val_loss: 0.1992 - val_accuracy: 0.9347\n",
            "Epoch 81/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0758 - accuracy: 0.9719 - val_loss: 0.2082 - val_accuracy: 0.9333\n",
            "Epoch 82/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0751 - accuracy: 0.9717 - val_loss: 0.2061 - val_accuracy: 0.9343\n",
            "Epoch 83/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0723 - accuracy: 0.9732 - val_loss: 0.2160 - val_accuracy: 0.9325\n",
            "Epoch 84/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.0759 - accuracy: 0.9720 - val_loss: 0.2157 - val_accuracy: 0.9324\n",
            "Epoch 85/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0774 - accuracy: 0.9715 - val_loss: 0.2049 - val_accuracy: 0.9348\n",
            "Epoch 86/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0727 - accuracy: 0.9733 - val_loss: 0.2080 - val_accuracy: 0.9324\n",
            "Epoch 87/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.0758 - accuracy: 0.9721 - val_loss: 0.2081 - val_accuracy: 0.9327\n",
            "Epoch 88/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0740 - accuracy: 0.9725 - val_loss: 0.2102 - val_accuracy: 0.9332\n",
            "Epoch 89/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0718 - accuracy: 0.9730 - val_loss: 0.2107 - val_accuracy: 0.9322\n",
            "Epoch 90/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0737 - accuracy: 0.9735 - val_loss: 0.2072 - val_accuracy: 0.9327\n",
            "Epoch 91/150\n",
            "240/240 [==============================] - 7s 28ms/step - loss: 0.0706 - accuracy: 0.9739 - val_loss: 0.2138 - val_accuracy: 0.9341\n",
            "Epoch 92/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.0705 - accuracy: 0.9736 - val_loss: 0.2095 - val_accuracy: 0.9337\n",
            "Epoch 93/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0716 - accuracy: 0.9738 - val_loss: 0.2140 - val_accuracy: 0.9333\n",
            "Epoch 94/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0749 - accuracy: 0.9731 - val_loss: 0.2196 - val_accuracy: 0.9309\n",
            "Epoch 95/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0711 - accuracy: 0.9730 - val_loss: 0.2097 - val_accuracy: 0.9325\n",
            "Epoch 96/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0712 - accuracy: 0.9747 - val_loss: 0.2157 - val_accuracy: 0.9303\n",
            "Epoch 97/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0735 - accuracy: 0.9720 - val_loss: 0.2100 - val_accuracy: 0.9351\n",
            "Epoch 98/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0674 - accuracy: 0.9757 - val_loss: 0.2070 - val_accuracy: 0.9341\n",
            "Epoch 99/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0646 - accuracy: 0.9766 - val_loss: 0.2163 - val_accuracy: 0.9327\n",
            "Epoch 100/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.0697 - accuracy: 0.9744 - val_loss: 0.2060 - val_accuracy: 0.9368\n",
            "Epoch 101/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.0679 - accuracy: 0.9757 - val_loss: 0.2127 - val_accuracy: 0.9340\n",
            "Epoch 102/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0684 - accuracy: 0.9754 - val_loss: 0.2057 - val_accuracy: 0.9362\n",
            "Epoch 103/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0659 - accuracy: 0.9756 - val_loss: 0.2114 - val_accuracy: 0.9320\n",
            "Epoch 104/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.0681 - accuracy: 0.9754 - val_loss: 0.2111 - val_accuracy: 0.9370\n",
            "Epoch 105/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.0674 - accuracy: 0.9750 - val_loss: 0.2128 - val_accuracy: 0.9338\n",
            "Epoch 106/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0676 - accuracy: 0.9746 - val_loss: 0.2113 - val_accuracy: 0.9330\n",
            "Epoch 107/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0678 - accuracy: 0.9758 - val_loss: 0.2261 - val_accuracy: 0.9326\n",
            "Epoch 108/150\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.0687 - accuracy: 0.9749 - val_loss: 0.2124 - val_accuracy: 0.9333\n",
            "Epoch 109/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0679 - accuracy: 0.9756 - val_loss: 0.2113 - val_accuracy: 0.9339\n",
            "Epoch 110/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0613 - accuracy: 0.9781 - val_loss: 0.2054 - val_accuracy: 0.9366\n",
            "Epoch 111/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0641 - accuracy: 0.9765 - val_loss: 0.2207 - val_accuracy: 0.9307\n",
            "Epoch 112/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.0625 - accuracy: 0.9768 - val_loss: 0.2181 - val_accuracy: 0.9349\n",
            "Epoch 113/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.0645 - accuracy: 0.9770 - val_loss: 0.2242 - val_accuracy: 0.9324\n",
            "Epoch 114/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0654 - accuracy: 0.9763 - val_loss: 0.2140 - val_accuracy: 0.9350\n",
            "Epoch 115/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0595 - accuracy: 0.9776 - val_loss: 0.2251 - val_accuracy: 0.9344\n",
            "Epoch 116/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0617 - accuracy: 0.9772 - val_loss: 0.2238 - val_accuracy: 0.9366\n",
            "Epoch 117/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.0650 - accuracy: 0.9764 - val_loss: 0.2185 - val_accuracy: 0.9349\n",
            "Epoch 118/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0646 - accuracy: 0.9764 - val_loss: 0.2112 - val_accuracy: 0.9362\n",
            "Epoch 119/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0651 - accuracy: 0.9772 - val_loss: 0.2251 - val_accuracy: 0.9337\n",
            "Epoch 120/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0613 - accuracy: 0.9783 - val_loss: 0.2219 - val_accuracy: 0.9342\n",
            "Epoch 121/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0688 - accuracy: 0.9748 - val_loss: 0.2162 - val_accuracy: 0.9352\n",
            "Epoch 122/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0596 - accuracy: 0.9785 - val_loss: 0.2285 - val_accuracy: 0.9337\n",
            "Epoch 123/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0647 - accuracy: 0.9771 - val_loss: 0.2212 - val_accuracy: 0.9337\n",
            "Epoch 124/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0637 - accuracy: 0.9780 - val_loss: 0.2157 - val_accuracy: 0.9349\n",
            "Epoch 125/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0611 - accuracy: 0.9784 - val_loss: 0.2128 - val_accuracy: 0.9348\n",
            "Epoch 126/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0627 - accuracy: 0.9768 - val_loss: 0.2216 - val_accuracy: 0.9337\n",
            "Epoch 127/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0625 - accuracy: 0.9777 - val_loss: 0.2305 - val_accuracy: 0.9352\n",
            "Epoch 128/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.0641 - accuracy: 0.9767 - val_loss: 0.2271 - val_accuracy: 0.9314\n",
            "Epoch 129/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.0625 - accuracy: 0.9775 - val_loss: 0.2202 - val_accuracy: 0.9324\n",
            "Epoch 130/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0624 - accuracy: 0.9786 - val_loss: 0.2220 - val_accuracy: 0.9346\n",
            "Epoch 131/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0609 - accuracy: 0.9784 - val_loss: 0.2118 - val_accuracy: 0.9361\n",
            "Epoch 132/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0569 - accuracy: 0.9790 - val_loss: 0.2278 - val_accuracy: 0.9327\n",
            "Epoch 133/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0603 - accuracy: 0.9785 - val_loss: 0.2215 - val_accuracy: 0.9363\n",
            "Epoch 134/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0573 - accuracy: 0.9796 - val_loss: 0.2258 - val_accuracy: 0.9318\n",
            "Epoch 135/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0623 - accuracy: 0.9776 - val_loss: 0.2257 - val_accuracy: 0.9356\n",
            "Epoch 136/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.0576 - accuracy: 0.9796 - val_loss: 0.2229 - val_accuracy: 0.9373\n",
            "Epoch 137/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0587 - accuracy: 0.9796 - val_loss: 0.2314 - val_accuracy: 0.9332\n",
            "Epoch 138/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0579 - accuracy: 0.9795 - val_loss: 0.2222 - val_accuracy: 0.9342\n",
            "Epoch 139/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0652 - accuracy: 0.9772 - val_loss: 0.2204 - val_accuracy: 0.9336\n",
            "Epoch 140/150\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.0620 - accuracy: 0.9781 - val_loss: 0.2266 - val_accuracy: 0.9327\n",
            "Epoch 141/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0616 - accuracy: 0.9783 - val_loss: 0.2216 - val_accuracy: 0.9333\n",
            "Epoch 142/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0616 - accuracy: 0.9770 - val_loss: 0.2264 - val_accuracy: 0.9331\n",
            "Epoch 143/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0605 - accuracy: 0.9788 - val_loss: 0.2271 - val_accuracy: 0.9323\n",
            "Epoch 144/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0554 - accuracy: 0.9806 - val_loss: 0.2238 - val_accuracy: 0.9347\n",
            "Epoch 145/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0592 - accuracy: 0.9797 - val_loss: 0.2252 - val_accuracy: 0.9351\n",
            "Epoch 146/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0582 - accuracy: 0.9782 - val_loss: 0.2280 - val_accuracy: 0.9337\n",
            "Epoch 147/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0588 - accuracy: 0.9797 - val_loss: 0.2282 - val_accuracy: 0.9341\n",
            "Epoch 148/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0599 - accuracy: 0.9784 - val_loss: 0.2269 - val_accuracy: 0.9353\n",
            "Epoch 149/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.0558 - accuracy: 0.9795 - val_loss: 0.2270 - val_accuracy: 0.9334\n",
            "Epoch 150/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.0588 - accuracy: 0.9781 - val_loss: 0.2257 - val_accuracy: 0.9350\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2257 - accuracy: 0.9350\n",
            "\n",
            "SUBMIT THIS BLOCK for the Competition\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.90      0.90      1211\n",
            "           1       0.99      0.98      0.99      1204\n",
            "           2       0.90      0.89      0.89      1216\n",
            "           3       0.92      0.94      0.93      1188\n",
            "           4       0.90      0.91      0.90      1252\n",
            "           5       0.99      0.99      0.99      1172\n",
            "           6       0.83      0.81      0.82      1189\n",
            "           7       0.95      0.99      0.97      1180\n",
            "           8       0.99      0.98      0.99      1162\n",
            "           9       0.99      0.95      0.97      1226\n",
            "\n",
            "    accuracy                           0.94     12000\n",
            "   macro avg       0.94      0.94      0.94     12000\n",
            "weighted avg       0.94      0.94      0.93     12000\n",
            "\n",
            "Testing Loss: 0.22569382190704346\n",
            "Testing Accuracy: 0.9350000023841858\n",
            "END SUBMISSION BLOCK\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 26, 26, 32)        0         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 26, 26, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 800)               7373600   \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 800)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 800)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                8010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,400,426\n",
            "Trainable params: 7,400,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTXLg2MJMFhy"
      },
      "source": [
        "## Plot the accuracy vs. validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2Z97VRkMIRh",
        "outputId": "97a4e8c5-b211-4fc7-f593-ccf3ed911f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "epoch_list = list(range(1, len(hist.history['accuracy']) + 1))\n",
        "plt.plot(epoch_list, hist.history['accuracy'], epoch_list, hist.history['val_accuracy'])\n",
        "plt.legend((\"Training Accuracy - Best\", \"Validation Accuracy - Best\"))\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epoch_list, hist.history['loss'], epoch_list, hist.history['val_loss'])\n",
        "plt.legend((\"Training Loss - Best\", \"Validation Loss - Best\"))\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Test Section"
      ],
      "metadata": {
        "id": "DFFCgjnAl7SK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# This is what is known as a Tensorflow (Keras) Sequential model\n",
        "# We will talk at some level about each of these layer types in class.\n",
        "#\n",
        "\n",
        "###Test####\n",
        "\n",
        "model_1 = Sequential()\n",
        "model_1.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 #kernel_initializer='he_normal',\n",
        "                 input_shape=input_shape))\n",
        "model_1.add(Dropout(0.7))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Conv2D(64, kernel_size=(3,3)))\n",
        "model_1.add(LeakyReLU(alpha=0.05))\n",
        "model_1.add(Dropout(0.7))\n",
        "model_1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(800))  \n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Dropout(0.7))\n",
        "model_1.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "my_callbacks_1 = [ModelCheckpoint('model_out.hdf5', monitor='val_accuracy',  mode='max', save_best_only=True, period=1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GClnAAG4mvpF",
        "outputId": "962ddb4d-951d-4e1b-b46a-a8e732e63d91"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flag to determine whether we use Keras' Image augmentation data generator\n",
        "augmentation = False\n",
        "\n",
        "#\n",
        "# Compile the model so we can fit it. Researching loss functions and optimizers\n",
        "# might be a good thing to do.\n",
        "#\n",
        "model_1.compile(loss=keras.losses.categorical_crossentropy, \n",
        "              optimizer=keras.optimizers.Adam(), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "if not augmentation:\n",
        "    #\n",
        "    # Fit the model.  Once the model is trained we'll evaluate the performance.\n",
        "    print('not using image augmentation')\n",
        "    hist1 = model_1.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=my_callbacks_1)\n",
        "else:\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "    hist1 = model_1.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                           steps_per_epoch=len(x_train) / batch_size, validation_data=(x_test, y_test),\n",
        "                           epochs=epochs, verbose=1, callbacks=my_callbacks_1, workers = 2)\n",
        "\n",
        "\n",
        "score_1 = model_1.evaluate(x_test, y_test)\n",
        "\n",
        "#\n",
        "# Predict on the test data and pass to metrics function\n",
        "yhat = np.argmax(model_1.predict(x_test), axis=-1)\n",
        "y_dec = decode_one_hot(y_test)\n",
        "\n",
        "print(\"\\nSUBMIT THIS BLOCK for the Competition\\n\")\n",
        "print(metrics.classification_report(y_dec, yhat))\n",
        "print(\"Testing Loss:\", score_1[0])\n",
        "print(\"Testing Accuracy:\", score_1[1])\n",
        "print(\"END SUBMISSION BLOCK\\n\")\n",
        "\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysjXCUMTmAro",
        "outputId": "d80fbb97-76c1-43cd-d45b-c7496aa172cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not using image augmentation\n",
            "Epoch 1/150\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.6579 - accuracy: 0.7607 - val_loss: 0.5974 - val_accuracy: 0.8525\n",
            "Epoch 2/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.4450 - accuracy: 0.8389 - val_loss: 0.4696 - val_accuracy: 0.8694\n",
            "Epoch 3/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.3942 - accuracy: 0.8568 - val_loss: 0.4185 - val_accuracy: 0.8848\n",
            "Epoch 4/150\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.3659 - accuracy: 0.8659 - val_loss: 0.3744 - val_accuracy: 0.8878\n",
            "Epoch 5/150\n",
            "236/240 [============================>.] - ETA: 0s - loss: 0.3428 - accuracy: 0.8728"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_list_1 = list(range(1, len(hist1.history['accuracy']) + 1))\n",
        "plt.plot(epoch_list_1, hist1.history['accuracy'], epoch_list_1, hist1.history['val_accuracy'])\n",
        "plt.legend((\"Training Accuracy - Test\", \"Validation Accuracy - Test\"))\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epoch_list_1, hist1.history['loss'], epoch_list_1, hist1.history['val_loss'])\n",
        "plt.legend((\"Training Loss - Test\", \"Validation Loss - Test\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1RMJEJXEmQ5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare\n",
        "\n",
        "plt.plot(epoch_list, hist.history['accuracy'], epoch_list, hist.history['val_accuracy'])\n",
        "plt.plot(epoch_list_1, hist1.history['accuracy'], epoch_list_1, hist1.history['val_accuracy'])\n",
        "plt.legend((\"Training Accuracy - Best\", \"Validation Accuracy - Best\", \"Training Accuracy - Test\", \"Validation Accuracy - Test\"))\n",
        "plt.show()\n",
        "\n",
        "#plt.plot(epoch_list_1, hist1.history['loss'], epoch_list_1, hist1.history['val_loss'])\n",
        "#plt.legend((\"Training Loss - Test\", \"Validation Loss - Test\"))\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "print(\"Testing Accuracy - Best:\", score[1])\n",
        "print(\"Testing Accuracy - Test:\", score_1[1])"
      ],
      "metadata": {
        "id": "Btx6l1w8nnN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-imOV3gbDji"
      },
      "source": [
        "## Visualization of Performance on the Test Set\n",
        "\n",
        "Here is a visualization of how well our classifier can do inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfsF8TlLwarT"
      },
      "source": [
        "import cv2\n",
        "from imutils import build_montages\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# initialize our list of output images\n",
        "images = []\n",
        "\n",
        "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
        "\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]\n",
        " \n",
        "# randomly select a few testing fashion items\n",
        "for i in np.random.choice(np.arange(0, len(y_test)), size=(16,)):\n",
        "\t# classify the clothing\n",
        "\tprobs = model.predict(x_test[np.newaxis, i])\n",
        "\tprediction = probs.argmax(axis=1)\n",
        "\tlabel = labelNames[prediction[0]]\n",
        " \n",
        "\t# extract the image from the testData if using \"channels_first\"\n",
        "\t# ordering\n",
        "\tif K.image_data_format() == \"channels_first\":\n",
        "\t\timage = (x_test[i][0] * 255).astype(\"uint8\")\n",
        " \n",
        "\t# otherwise we are using \"channels_last\" ordering\n",
        "\telse:\n",
        "\t\timage = (x_test[i] * 255).astype(\"uint8\")\n",
        "    # initialize the text label color as green (correct)\n",
        "\tcolor = (0, 255, 0)\n",
        " \n",
        "\t# otherwise, the class label prediction is incorrect\n",
        "\tif prediction[0] != np.argmax(y_test[i]):\n",
        "\t\tcolor = (0, 0, 255)\n",
        " \n",
        "\t# merge the channels into one image and resize the image from\n",
        "\t# 28x28 to 96x96 so we can better see it and then draw the\n",
        "\t# predicted label on the image\n",
        "\timage = cv2.merge([image] * 3)\n",
        "\timage = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
        "\tcv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
        "\t\tcolor, 2)\n",
        " \n",
        "\t# add the image to our list of output images\n",
        "\timages.append(image)\n",
        "# construct the montage for the images\n",
        "montage = build_montages(images, (96, 96), (4, 4))[0]\n",
        " \n",
        "# show the output montage\n",
        "cv2_imshow( montage)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMDjuN_anxKM"
      },
      "source": [
        "\n",
        "#Need to check 50/200\n",
        "#epochs = 50                 # Number of Training Epochs\n",
        "#num_classes = 10            # This is the number of classes in the Fashion MNIST dataset\n",
        "#batch_size = 200          # This parameter can be adjusted\n",
        "#img_rows, img_cols = 28, 28 # Pixel sizes of the Images in the Dataset\n",
        "\n",
        "#Current Best\n",
        "epochs = 40                 # Number of Training Epochs\n",
        "num_classes = 10            # This is the number of classes in the Fashion MNIST dataset\n",
        "batch_size = 300          # This parameter can be adjusted\n",
        "img_rows, img_cols = 28, 28 # Pixel sizes of the Images in the Dataset\n",
        "\n",
        "#\n",
        "# This is what is known as a Tensorflow (Keras) Sequential model\n",
        "# We will talk at some level about each of these layer types in class.\n",
        "#\n",
        "\n",
        "###Test####\n",
        "\n",
        "model_1 = Sequential()\n",
        "model_1.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 #kernel_initializer='he_normal',\n",
        "                 input_shape=input_shape))\n",
        "model_1.add(Dropout(0.7))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Conv2D(64, kernel_size=(3,3)))\n",
        "model_1.add(LeakyReLU(alpha=0.05))\n",
        "model_1.add(Dropout(0.6))\n",
        "model_1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(1000))  \n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "my_callbacks = [ModelCheckpoint('model_out.hdf5', monitor='acc', save_best_only=True, period=1)]\n",
        "\n",
        "\n",
        "#Testing Accuracy - Test: 0.9271717071533203"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}