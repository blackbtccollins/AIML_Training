{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion MNIST Competition",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackbtccollins/AIML_Training/blob/main/class/Blackburn_submissionv4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHwxGemYV_FT"
      },
      "source": [
        "# Fashion MNIST Competition! - Blackburn Submission\n",
        "**Author**: T. Blackburn\n",
        "\n",
        "**Updates**: New Version\n",
        "\n",
        "## Problem\n",
        "\n",
        "Classify images from the \"Fashion MNIST\" data set.   Optimize the test accuracy.\n",
        "\n",
        "## Metrics\n",
        "\n",
        "This competition is evaluated on the mean Dice coefficient. The Dice coefficient can be used to compare the pixel-wise agreement between a predicted segmentation and its corresponding ground truth. The formula is given by:![alt text](https://user-images.githubusercontent.com/26015273/41822460-2ca0a90a-77f0-11e8-9c71-7e88fa6b5c61.gif)\n",
        "\n",
        "\n",
        "The double sum is over the observations `i`, whose number is `N`, and the categories `c`, whose number is `C`. The term `1_{y_i \\in C_c}` is the indicator function of the `i`th observation belonging to the `c`th category. The `p_{model}[y_i \\in C_c]` is the probability predicted by the model for the `i`th observation to belong to the `c`th category. When there are more than two categories, the neural network outputs a vector of `C` probabilities, each giving the probability that the network input should be classified as belonging to the respective category. When the number of categories is just two, the neural network outputs a single probability `\\hat{y}_i`, with the other one being `1` minus the output. This is why the binary cross entropy looks a bit different from categorical cross entropy, despite being a special case of it.\n",
        "\n",
        "## Dataset\n",
        "\n",
        "This dataset is the Fashion MNIST dataset\n",
        "\n",
        "Recently, the researchers at Zalando, an e-commerce company, introduced Fashion MNIST as a drop-in replacement for the original MNIST dataset. Like MNIST, Fashion MNIST consists of a training set consisting of 60,000 examples belonging to 10 different classes and a test set of 10,000 examples. Each training example is a gray-scale image, 28x28 in size. The authors of the work further claim that the Fashion MNIST should actually replace MNIST dataset for benchmarking of new Machine Learning or Computer Vision models.\n",
        "\n",
        "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n",
        "\n",
        "The Labels are:  \n",
        "0 T-shirt/top\n",
        "1 Trouser\n",
        "2 Pullover\n",
        "3 Dress\n",
        "4 Coat\n",
        "5 Sandal\n",
        "6 Shirt\n",
        "7 Sneaker\n",
        "8 Bag\n",
        "9 Ankle boot \n",
        "\n",
        "## Objective\n",
        "\n",
        "In this competition, you can try different variations of the CNN model given as a reference, you may evaluate techniques to squeeze more performance out of a CNN, or you might even try a completely different model, neural network or otherwise.  You will note that there are tips/tricks/techniques documented in many locations on the internet that could be useful.\n",
        "\n",
        "## Rules and Timeline\n",
        "\n",
        "The primary measure for the competition will be the accuracy of prediction on the test data.  Ties will be broken by Precision accuracy first, then Recall Accuracy if needed.\n",
        "\n",
        "The results will be revealed at the end of the last day of class.  Please submit your Metrics blocks (Starts with SUBMIT... and ends with END SUBMISSION) to instructors (wtnewman@raytheon.com) before lunch.\n",
        "\n",
        "A prize will be given to the top finisher(s) based on the judgement of the instructor and the availability of prizes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0A2_Mo0KxWc"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten,  Conv2D, MaxPooling2D, Activation, BatchNormalization\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import TensorBoard,  ModelCheckpoint\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import os\n",
        "%matplotlib inline\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y6VjlzZLKPB"
      },
      "source": [
        "## Set Up Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtL1H333LHGz"
      },
      "source": [
        "epochs = 150                 # Number of Training Epochs\n",
        "num_classes = 10            # This is the number of classes in the Fashion MNIST dataset\n",
        "batch_size = 200          # This parameter can be adjusted\n",
        "img_rows, img_cols = 28, 28 # Pixel sizes of the Images in the Dataset"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SW52B7dT9H5"
      },
      "source": [
        "## Gather and Process Fashion MNIST data\n",
        "\n",
        "1. First, collect the data from Keras (our goal is someday that our organizational data is this easy to get!)\n",
        "2. Then split into train and test sets.\n",
        "3. Next we need to process the data into the proper shape for the CNN\n",
        "4. Then scale the floats to land between 0 and 1.  Often times we use sklearn's MinMaxScaler for this, but in this case we're going for simplicity.\n",
        "5. Next take the y_train and y_test labels and encode them one-hot.  This will enable the CNN to function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZENio2YLPUy",
        "outputId": "0136d47e-f6a1-4bb5-f014-7b423107b10b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Grab the data from the keras repository\n",
        "\n",
        "mnist_data = fashion_mnist.load_data()\n",
        "x = mnist_data[0][0]\n",
        "y = mnist_data[0][1]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=41)\n",
        "\n",
        "# Process the date into the right tensor shape.  This is a good practice, but\n",
        "# usually tensorflow uses channels last (the 'else' here)\n",
        "\n",
        "if K.image_data_format() == \"channels first\":\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "    \n",
        "#\n",
        "#  Cast to a 32 bit float and then scale so the value is a float between 0 and 1\n",
        "    \n",
        "x_train = x_train.astype(\"float32\")\n",
        "x_test = x_test.astype(\"float32\")\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "#\n",
        "# Convert Class Vector to Binary Class Matrices (one-hot encoding).\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(y_test.shape)\n",
        "\n",
        "#\n",
        "# Function to decode one-hot encoding later on when we want to evaluate performance.\n",
        "def decode_one_hot(y):\n",
        "    y_classes = [np.argmax(yi, axis=None, out=None) for yi in y]\n",
        "    return y_classes\n",
        "\n",
        "'''\n",
        "\n",
        "Below we're experimenting with the Keras ImageDataGenerator.  From my experience, if these parameters\n",
        "are set too aggressively, the loss/accuracy will either never improve or it will take too long to improve.\n",
        "Below is an example of a complex data augmentation regime.  This is just for reference.  See my more simple\n",
        "one at the bottom.\n",
        "\n",
        "    \n",
        "datagen = ImageDataGenerator(rotation_range=0.5, \n",
        "                                 zoom_range=0.1,\n",
        "                                 featurewise_center=True,\n",
        "                                 #featurewise_std_normalization=True,\n",
        "                                 width_shift_range=0.1, \n",
        "                                 height_shift_range=0.1, \n",
        "                                 shear_range=0.1,\n",
        "                                 horizontal_flip=True, \n",
        "                                 fill_mode=\"nearest\")\n",
        "'''\n",
        "#\n",
        "#  Set up our Image Augmentation Data Generator\n",
        "#\n",
        "datagen = ImageDataGenerator(rotation_range=5)\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FcFnUPDLvnO"
      },
      "source": [
        "## Build the Model\n",
        "\n",
        "* In this example, we define the below block as a Sequential Model. \n",
        "* See the excellent [Keras Documentation](https://keras.io/guides/sequential_model/) on Sequential Models for info.\n",
        "* Many of these parameters can be experimented with.  The documentation will help you understand how much to experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EWdo8mALXB9",
        "outputId": "ead6d30c-4a2d-4878-d7f8-269c691ea0b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# This is what is known as a Tensorflow (Keras) Sequential model\n",
        "# We will talk at some level about each of these layer types in class.\n",
        "#\n",
        "\n",
        "###Best####\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 #kernel_initializer='he_normal',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, kernel_size=(3,3)))\n",
        "model.add(LeakyReLU(alpha=0.05))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(800))  \n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "my_callbacks = [ModelCheckpoint('model_out.hdf5', monitor='val_accuracy',  mode='max', save_best_only=True, period=1)]\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# This is what is known as a Tensorflow (Keras) Sequential model\n",
        "# We will talk at some level about each of these layer types in class.\n",
        "#\n",
        "\n",
        "###BEST - Save ####\n",
        "\n",
        "#model = Sequential()\n",
        "#\n",
        "#model.add(Conv2D(32, kernel_size=(3,3), input_shape=input_shape))\n",
        "#model.add(Dropout(0.3))\n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Conv2D(64, kernel_size=(3,3)))\n",
        "#model.add(LeakyReLU(alpha=0.05))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(100))  \n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "#model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "#\n",
        "#my_callbacks = [ModelCheckpoint('model_out.hdf5', monitor='acc', save_best_only=True, period=1)]"
      ],
      "metadata": {
        "id": "BUyaq5L-Q1Di"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvIfjap-L8TO"
      },
      "source": [
        "## Fit and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5U20dV1L-eP",
        "outputId": "451ef52d-57ff-4ba4-c0d9-36fbc0b3acf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Flag to determine whether we use Keras' Image augmentation data generator\n",
        "augmentation = False\n",
        "\n",
        "#\n",
        "# Compile the model so we can fit it. Researching loss functions and optimizers\n",
        "# might be a good thing to do.\n",
        "#\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, \n",
        "              optimizer=keras.optimizers.Adam(), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "if not augmentation:\n",
        "    #\n",
        "    # Fit the model.  Once the model is trained we'll evaluate the performance.\n",
        "    print('not using image augmentation')\n",
        "    hist = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=my_callbacks)\n",
        "else:\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "    hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                           steps_per_epoch=len(x_train) / batch_size, validation_data=(x_test, y_test),\n",
        "                           epochs=epochs, verbose=1, callbacks=my_callbacks, workers = 2)\n",
        "\n",
        "\n",
        "score = model.evaluate(x_test, y_test)\n",
        "\n",
        "#\n",
        "# Predict on the test data and pass to metrics function\n",
        "yhat = np.argmax(model.predict(x_test), axis=-1)\n",
        "y_dec = decode_one_hot(y_test)\n",
        "\n",
        "print(\"\\nSUBMIT THIS BLOCK for the Competition\\n\")\n",
        "print(metrics.classification_report(y_dec, yhat))\n",
        "print(\"Testing Loss:\", score[0])\n",
        "print(\"Testing Accuracy:\", score[1])\n",
        "print(\"END SUBMISSION BLOCK\\n\")\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not using image augmentation\n",
            "Epoch 1/150\n",
            "270/270 [==============================] - 6s 19ms/step - loss: 0.6162 - accuracy: 0.7799 - val_loss: 0.4989 - val_accuracy: 0.8623\n",
            "Epoch 2/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.3920 - accuracy: 0.8571 - val_loss: 0.4164 - val_accuracy: 0.8833\n",
            "Epoch 3/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.3367 - accuracy: 0.8767 - val_loss: 0.3307 - val_accuracy: 0.8978\n",
            "Epoch 4/150\n",
            "270/270 [==============================] - 5s 20ms/step - loss: 0.3083 - accuracy: 0.8860 - val_loss: 0.3110 - val_accuracy: 0.9043\n",
            "Epoch 5/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.2840 - accuracy: 0.8949 - val_loss: 0.2960 - val_accuracy: 0.9113\n",
            "Epoch 6/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.2655 - accuracy: 0.9005 - val_loss: 0.2608 - val_accuracy: 0.9150\n",
            "Epoch 7/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.2539 - accuracy: 0.9062 - val_loss: 0.2530 - val_accuracy: 0.9142\n",
            "Epoch 8/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.2388 - accuracy: 0.9108 - val_loss: 0.2534 - val_accuracy: 0.9198\n",
            "Epoch 9/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.2273 - accuracy: 0.9149 - val_loss: 0.2408 - val_accuracy: 0.9200\n",
            "Epoch 10/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.2192 - accuracy: 0.9168 - val_loss: 0.2287 - val_accuracy: 0.9225\n",
            "Epoch 11/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.2101 - accuracy: 0.9210 - val_loss: 0.2201 - val_accuracy: 0.9222\n",
            "Epoch 12/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.1996 - accuracy: 0.9256 - val_loss: 0.2196 - val_accuracy: 0.9267\n",
            "Epoch 13/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.1928 - accuracy: 0.9275 - val_loss: 0.2075 - val_accuracy: 0.9283\n",
            "Epoch 14/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1887 - accuracy: 0.9277 - val_loss: 0.2186 - val_accuracy: 0.9230\n",
            "Epoch 15/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.1824 - accuracy: 0.9311 - val_loss: 0.2080 - val_accuracy: 0.9293\n",
            "Epoch 16/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.1783 - accuracy: 0.9327 - val_loss: 0.2016 - val_accuracy: 0.9303\n",
            "Epoch 17/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1718 - accuracy: 0.9350 - val_loss: 0.1961 - val_accuracy: 0.9328\n",
            "Epoch 18/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1648 - accuracy: 0.9380 - val_loss: 0.1919 - val_accuracy: 0.9307\n",
            "Epoch 19/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1608 - accuracy: 0.9391 - val_loss: 0.1882 - val_accuracy: 0.9325\n",
            "Epoch 20/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1565 - accuracy: 0.9409 - val_loss: 0.1881 - val_accuracy: 0.9305\n",
            "Epoch 21/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1501 - accuracy: 0.9424 - val_loss: 0.1965 - val_accuracy: 0.9282\n",
            "Epoch 22/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1483 - accuracy: 0.9441 - val_loss: 0.1843 - val_accuracy: 0.9327\n",
            "Epoch 23/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1448 - accuracy: 0.9449 - val_loss: 0.1895 - val_accuracy: 0.9315\n",
            "Epoch 24/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.1405 - accuracy: 0.9471 - val_loss: 0.1809 - val_accuracy: 0.9370\n",
            "Epoch 25/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.1361 - accuracy: 0.9482 - val_loss: 0.1839 - val_accuracy: 0.9350\n",
            "Epoch 26/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1325 - accuracy: 0.9496 - val_loss: 0.1831 - val_accuracy: 0.9347\n",
            "Epoch 27/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1297 - accuracy: 0.9516 - val_loss: 0.1778 - val_accuracy: 0.9357\n",
            "Epoch 28/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1294 - accuracy: 0.9520 - val_loss: 0.1790 - val_accuracy: 0.9358\n",
            "Epoch 29/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1257 - accuracy: 0.9530 - val_loss: 0.1801 - val_accuracy: 0.9352\n",
            "Epoch 30/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1224 - accuracy: 0.9539 - val_loss: 0.1805 - val_accuracy: 0.9365\n",
            "Epoch 31/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.1202 - accuracy: 0.9549 - val_loss: 0.1786 - val_accuracy: 0.9383\n",
            "Epoch 32/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1205 - accuracy: 0.9547 - val_loss: 0.1766 - val_accuracy: 0.9383\n",
            "Epoch 33/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1154 - accuracy: 0.9570 - val_loss: 0.1785 - val_accuracy: 0.9357\n",
            "Epoch 34/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1158 - accuracy: 0.9566 - val_loss: 0.1786 - val_accuracy: 0.9362\n",
            "Epoch 35/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1130 - accuracy: 0.9569 - val_loss: 0.1776 - val_accuracy: 0.9365\n",
            "Epoch 36/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1116 - accuracy: 0.9583 - val_loss: 0.1762 - val_accuracy: 0.9373\n",
            "Epoch 37/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1072 - accuracy: 0.9593 - val_loss: 0.1832 - val_accuracy: 0.9357\n",
            "Epoch 38/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1110 - accuracy: 0.9580 - val_loss: 0.1815 - val_accuracy: 0.9348\n",
            "Epoch 39/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1060 - accuracy: 0.9600 - val_loss: 0.1781 - val_accuracy: 0.9383\n",
            "Epoch 40/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1056 - accuracy: 0.9602 - val_loss: 0.1792 - val_accuracy: 0.9375\n",
            "Epoch 41/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1035 - accuracy: 0.9606 - val_loss: 0.1820 - val_accuracy: 0.9342\n",
            "Epoch 42/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1042 - accuracy: 0.9617 - val_loss: 0.1815 - val_accuracy: 0.9350\n",
            "Epoch 43/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.1003 - accuracy: 0.9632 - val_loss: 0.1789 - val_accuracy: 0.9387\n",
            "Epoch 44/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.1006 - accuracy: 0.9619 - val_loss: 0.1800 - val_accuracy: 0.9350\n",
            "Epoch 45/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0962 - accuracy: 0.9640 - val_loss: 0.1781 - val_accuracy: 0.9383\n",
            "Epoch 46/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0977 - accuracy: 0.9629 - val_loss: 0.1808 - val_accuracy: 0.9368\n",
            "Epoch 47/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0936 - accuracy: 0.9654 - val_loss: 0.1748 - val_accuracy: 0.9405\n",
            "Epoch 48/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0936 - accuracy: 0.9646 - val_loss: 0.1770 - val_accuracy: 0.9380\n",
            "Epoch 49/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0942 - accuracy: 0.9648 - val_loss: 0.1829 - val_accuracy: 0.9355\n",
            "Epoch 50/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0893 - accuracy: 0.9660 - val_loss: 0.1868 - val_accuracy: 0.9377\n",
            "Epoch 51/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0918 - accuracy: 0.9668 - val_loss: 0.1807 - val_accuracy: 0.9390\n",
            "Epoch 52/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0920 - accuracy: 0.9660 - val_loss: 0.1794 - val_accuracy: 0.9370\n",
            "Epoch 53/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0914 - accuracy: 0.9659 - val_loss: 0.1877 - val_accuracy: 0.9352\n",
            "Epoch 54/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0874 - accuracy: 0.9665 - val_loss: 0.1841 - val_accuracy: 0.9362\n",
            "Epoch 55/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0863 - accuracy: 0.9684 - val_loss: 0.1862 - val_accuracy: 0.9332\n",
            "Epoch 56/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0826 - accuracy: 0.9683 - val_loss: 0.1810 - val_accuracy: 0.9377\n",
            "Epoch 57/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0875 - accuracy: 0.9672 - val_loss: 0.1829 - val_accuracy: 0.9388\n",
            "Epoch 58/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0858 - accuracy: 0.9683 - val_loss: 0.1838 - val_accuracy: 0.9342\n",
            "Epoch 59/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0836 - accuracy: 0.9690 - val_loss: 0.1796 - val_accuracy: 0.9387\n",
            "Epoch 60/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0883 - accuracy: 0.9679 - val_loss: 0.1873 - val_accuracy: 0.9337\n",
            "Epoch 61/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0838 - accuracy: 0.9691 - val_loss: 0.1893 - val_accuracy: 0.9337\n",
            "Epoch 62/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0809 - accuracy: 0.9697 - val_loss: 0.1862 - val_accuracy: 0.9357\n",
            "Epoch 63/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0839 - accuracy: 0.9688 - val_loss: 0.1800 - val_accuracy: 0.9365\n",
            "Epoch 64/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0809 - accuracy: 0.9695 - val_loss: 0.1837 - val_accuracy: 0.9365\n",
            "Epoch 65/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0810 - accuracy: 0.9697 - val_loss: 0.1800 - val_accuracy: 0.9395\n",
            "Epoch 66/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0792 - accuracy: 0.9718 - val_loss: 0.1818 - val_accuracy: 0.9358\n",
            "Epoch 67/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0776 - accuracy: 0.9714 - val_loss: 0.1795 - val_accuracy: 0.9407\n",
            "Epoch 68/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0774 - accuracy: 0.9709 - val_loss: 0.1871 - val_accuracy: 0.9355\n",
            "Epoch 69/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0771 - accuracy: 0.9718 - val_loss: 0.1873 - val_accuracy: 0.9337\n",
            "Epoch 70/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0771 - accuracy: 0.9714 - val_loss: 0.1795 - val_accuracy: 0.9393\n",
            "Epoch 71/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0774 - accuracy: 0.9710 - val_loss: 0.1804 - val_accuracy: 0.9390\n",
            "Epoch 72/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0782 - accuracy: 0.9714 - val_loss: 0.1790 - val_accuracy: 0.9395\n",
            "Epoch 73/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0751 - accuracy: 0.9721 - val_loss: 0.1845 - val_accuracy: 0.9347\n",
            "Epoch 74/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0762 - accuracy: 0.9719 - val_loss: 0.1783 - val_accuracy: 0.9398\n",
            "Epoch 75/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0781 - accuracy: 0.9711 - val_loss: 0.1868 - val_accuracy: 0.9368\n",
            "Epoch 76/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0715 - accuracy: 0.9736 - val_loss: 0.1872 - val_accuracy: 0.9375\n",
            "Epoch 77/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0726 - accuracy: 0.9728 - val_loss: 0.1897 - val_accuracy: 0.9383\n",
            "Epoch 78/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0736 - accuracy: 0.9722 - val_loss: 0.1832 - val_accuracy: 0.9407\n",
            "Epoch 79/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0719 - accuracy: 0.9732 - val_loss: 0.1866 - val_accuracy: 0.9397\n",
            "Epoch 80/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0726 - accuracy: 0.9732 - val_loss: 0.1983 - val_accuracy: 0.9347\n",
            "Epoch 81/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0679 - accuracy: 0.9749 - val_loss: 0.1967 - val_accuracy: 0.9378\n",
            "Epoch 82/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0712 - accuracy: 0.9745 - val_loss: 0.1873 - val_accuracy: 0.9380\n",
            "Epoch 83/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0706 - accuracy: 0.9738 - val_loss: 0.1945 - val_accuracy: 0.9378\n",
            "Epoch 84/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0750 - accuracy: 0.9736 - val_loss: 0.1898 - val_accuracy: 0.9388\n",
            "Epoch 85/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0704 - accuracy: 0.9735 - val_loss: 0.1950 - val_accuracy: 0.9373\n",
            "Epoch 86/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0655 - accuracy: 0.9760 - val_loss: 0.2036 - val_accuracy: 0.9343\n",
            "Epoch 87/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0685 - accuracy: 0.9743 - val_loss: 0.1914 - val_accuracy: 0.9372\n",
            "Epoch 88/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0709 - accuracy: 0.9738 - val_loss: 0.1965 - val_accuracy: 0.9347\n",
            "Epoch 89/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0687 - accuracy: 0.9748 - val_loss: 0.1920 - val_accuracy: 0.9400\n",
            "Epoch 90/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0696 - accuracy: 0.9753 - val_loss: 0.1987 - val_accuracy: 0.9347\n",
            "Epoch 91/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0667 - accuracy: 0.9751 - val_loss: 0.1933 - val_accuracy: 0.9377\n",
            "Epoch 92/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0681 - accuracy: 0.9752 - val_loss: 0.1846 - val_accuracy: 0.9400\n",
            "Epoch 93/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0681 - accuracy: 0.9752 - val_loss: 0.1901 - val_accuracy: 0.9390\n",
            "Epoch 94/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0686 - accuracy: 0.9750 - val_loss: 0.1893 - val_accuracy: 0.9382\n",
            "Epoch 95/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0659 - accuracy: 0.9758 - val_loss: 0.2035 - val_accuracy: 0.9343\n",
            "Epoch 96/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0649 - accuracy: 0.9765 - val_loss: 0.1966 - val_accuracy: 0.9367\n",
            "Epoch 97/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0675 - accuracy: 0.9755 - val_loss: 0.1915 - val_accuracy: 0.9382\n",
            "Epoch 98/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0692 - accuracy: 0.9755 - val_loss: 0.1914 - val_accuracy: 0.9380\n",
            "Epoch 99/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0637 - accuracy: 0.9763 - val_loss: 0.1854 - val_accuracy: 0.9385\n",
            "Epoch 100/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0643 - accuracy: 0.9758 - val_loss: 0.1960 - val_accuracy: 0.9382\n",
            "Epoch 101/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0701 - accuracy: 0.9745 - val_loss: 0.1924 - val_accuracy: 0.9383\n",
            "Epoch 102/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0611 - accuracy: 0.9772 - val_loss: 0.1976 - val_accuracy: 0.9402\n",
            "Epoch 103/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0641 - accuracy: 0.9763 - val_loss: 0.1956 - val_accuracy: 0.9380\n",
            "Epoch 104/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0650 - accuracy: 0.9761 - val_loss: 0.1956 - val_accuracy: 0.9373\n",
            "Epoch 105/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0681 - accuracy: 0.9758 - val_loss: 0.1921 - val_accuracy: 0.9362\n",
            "Epoch 106/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0604 - accuracy: 0.9784 - val_loss: 0.2004 - val_accuracy: 0.9340\n",
            "Epoch 107/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0640 - accuracy: 0.9777 - val_loss: 0.2092 - val_accuracy: 0.9347\n",
            "Epoch 108/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0623 - accuracy: 0.9773 - val_loss: 0.1982 - val_accuracy: 0.9377\n",
            "Epoch 109/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0619 - accuracy: 0.9781 - val_loss: 0.1991 - val_accuracy: 0.9375\n",
            "Epoch 110/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0637 - accuracy: 0.9769 - val_loss: 0.1973 - val_accuracy: 0.9375\n",
            "Epoch 111/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0672 - accuracy: 0.9753 - val_loss: 0.2029 - val_accuracy: 0.9360\n",
            "Epoch 112/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0623 - accuracy: 0.9780 - val_loss: 0.1965 - val_accuracy: 0.9375\n",
            "Epoch 113/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0598 - accuracy: 0.9785 - val_loss: 0.2043 - val_accuracy: 0.9385\n",
            "Epoch 114/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0613 - accuracy: 0.9782 - val_loss: 0.2028 - val_accuracy: 0.9350\n",
            "Epoch 115/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0590 - accuracy: 0.9784 - val_loss: 0.2144 - val_accuracy: 0.9342\n",
            "Epoch 116/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0638 - accuracy: 0.9772 - val_loss: 0.1994 - val_accuracy: 0.9367\n",
            "Epoch 117/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0608 - accuracy: 0.9783 - val_loss: 0.1937 - val_accuracy: 0.9400\n",
            "Epoch 118/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0635 - accuracy: 0.9770 - val_loss: 0.1967 - val_accuracy: 0.9392\n",
            "Epoch 119/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0631 - accuracy: 0.9774 - val_loss: 0.1986 - val_accuracy: 0.9365\n",
            "Epoch 120/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0616 - accuracy: 0.9780 - val_loss: 0.2096 - val_accuracy: 0.9352\n",
            "Epoch 121/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0594 - accuracy: 0.9789 - val_loss: 0.1983 - val_accuracy: 0.9380\n",
            "Epoch 122/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0634 - accuracy: 0.9778 - val_loss: 0.2020 - val_accuracy: 0.9377\n",
            "Epoch 123/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0619 - accuracy: 0.9781 - val_loss: 0.2000 - val_accuracy: 0.9385\n",
            "Epoch 124/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0600 - accuracy: 0.9780 - val_loss: 0.2052 - val_accuracy: 0.9342\n",
            "Epoch 125/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0617 - accuracy: 0.9777 - val_loss: 0.1982 - val_accuracy: 0.9405\n",
            "Epoch 126/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0595 - accuracy: 0.9790 - val_loss: 0.1956 - val_accuracy: 0.9400\n",
            "Epoch 127/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0600 - accuracy: 0.9781 - val_loss: 0.2073 - val_accuracy: 0.9372\n",
            "Epoch 128/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0601 - accuracy: 0.9785 - val_loss: 0.1975 - val_accuracy: 0.9393\n",
            "Epoch 129/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0583 - accuracy: 0.9796 - val_loss: 0.2010 - val_accuracy: 0.9355\n",
            "Epoch 130/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0587 - accuracy: 0.9792 - val_loss: 0.2014 - val_accuracy: 0.9422\n",
            "Epoch 131/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0573 - accuracy: 0.9797 - val_loss: 0.1990 - val_accuracy: 0.9395\n",
            "Epoch 132/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0591 - accuracy: 0.9784 - val_loss: 0.2097 - val_accuracy: 0.9335\n",
            "Epoch 133/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0574 - accuracy: 0.9799 - val_loss: 0.2045 - val_accuracy: 0.9355\n",
            "Epoch 134/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0600 - accuracy: 0.9787 - val_loss: 0.2121 - val_accuracy: 0.9367\n",
            "Epoch 135/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0597 - accuracy: 0.9800 - val_loss: 0.2038 - val_accuracy: 0.9397\n",
            "Epoch 136/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0591 - accuracy: 0.9791 - val_loss: 0.2107 - val_accuracy: 0.9385\n",
            "Epoch 137/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0587 - accuracy: 0.9791 - val_loss: 0.2083 - val_accuracy: 0.9393\n",
            "Epoch 138/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0597 - accuracy: 0.9786 - val_loss: 0.2056 - val_accuracy: 0.9377\n",
            "Epoch 139/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0560 - accuracy: 0.9800 - val_loss: 0.2113 - val_accuracy: 0.9372\n",
            "Epoch 140/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0567 - accuracy: 0.9796 - val_loss: 0.2086 - val_accuracy: 0.9393\n",
            "Epoch 141/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0609 - accuracy: 0.9783 - val_loss: 0.2097 - val_accuracy: 0.9373\n",
            "Epoch 142/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0581 - accuracy: 0.9799 - val_loss: 0.2115 - val_accuracy: 0.9362\n",
            "Epoch 143/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0545 - accuracy: 0.9810 - val_loss: 0.2083 - val_accuracy: 0.9390\n",
            "Epoch 144/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0561 - accuracy: 0.9800 - val_loss: 0.2097 - val_accuracy: 0.9388\n",
            "Epoch 145/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0566 - accuracy: 0.9793 - val_loss: 0.2097 - val_accuracy: 0.9358\n",
            "Epoch 146/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0551 - accuracy: 0.9805 - val_loss: 0.2124 - val_accuracy: 0.9372\n",
            "Epoch 147/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0556 - accuracy: 0.9808 - val_loss: 0.2045 - val_accuracy: 0.9387\n",
            "Epoch 148/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0568 - accuracy: 0.9798 - val_loss: 0.2075 - val_accuracy: 0.9385\n",
            "Epoch 149/150\n",
            "270/270 [==============================] - 5s 18ms/step - loss: 0.0574 - accuracy: 0.9798 - val_loss: 0.2064 - val_accuracy: 0.9403\n",
            "Epoch 150/150\n",
            "270/270 [==============================] - 5s 19ms/step - loss: 0.0579 - accuracy: 0.9804 - val_loss: 0.2068 - val_accuracy: 0.9403\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9403\n",
            "\n",
            "SUBMIT THIS BLOCK for the Competition\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90       588\n",
            "           1       0.99      0.99      0.99       564\n",
            "           2       0.91      0.91      0.91       607\n",
            "           3       0.92      0.95      0.94       593\n",
            "           4       0.90      0.90      0.90       608\n",
            "           5       1.00      0.99      1.00       618\n",
            "           6       0.84      0.83      0.83       609\n",
            "           7       0.96      0.98      0.97       590\n",
            "           8       0.99      1.00      0.99       575\n",
            "           9       0.99      0.97      0.98       648\n",
            "\n",
            "    accuracy                           0.94      6000\n",
            "   macro avg       0.94      0.94      0.94      6000\n",
            "weighted avg       0.94      0.94      0.94      6000\n",
            "\n",
            "Testing Loss: 0.20680482685565948\n",
            "Testing Accuracy: 0.9403333067893982\n",
            "END SUBMISSION BLOCK\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 26, 26, 32)        0         \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 26, 26, 32)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 12, 12, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 800)               7373600   \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 800)               0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 800)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                8010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,400,426\n",
            "Trainable params: 7,400,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTXLg2MJMFhy"
      },
      "source": [
        "## Plot the accuracy vs. validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2Z97VRkMIRh",
        "outputId": "8c1373b1-2e75-4796-cda1-dda46a170a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "epoch_list = list(range(1, len(hist.history['accuracy']) + 1))\n",
        "plt.plot(epoch_list, hist.history['accuracy'], epoch_list, hist.history['val_accuracy'])\n",
        "plt.legend((\"Training Accuracy - Best\", \"Validation Accuracy - Best\"))\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epoch_list, hist.history['loss'], epoch_list, hist.history['val_loss'])\n",
        "plt.legend((\"Training Loss - Best\", \"Validation Loss - Best\"))\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3xUxfr48c+TQhLSKAktARKQGiDBhKKIgFwFGyCigqJiAfXa9RZsV6/lJ371eu16sSEWUFEUFUUREBVQQgi9hxYCIZCekLY7vz9mk2wSSoBAgH3er1de2T17zmTOZneemTlzZsQYg1JKKc/jVd8ZUEopVT80ACillIfSAKCUUh5KA4BSSnkoDQBKKeWhfOo7A0cjLCzMREVF1Xc2lFLqtLJs2bJ9xpjw6ttPqwAQFRVFYmJifWdDKaVOKyKy/WDbtQtIKaU8lAYApZTyUBoAlFLKQ2kAUEopD6UBQCmlPJQGAKWU8lAaAJRSykNpAFBKqRPMGMOvmzKYuTyV4jJHjddzi0pZtj2LRVv24XTWnKL/QEnNY+rCaXUjmFJK1ZUDJQ78fb0QEYpKHWzdV0CHZkH4eHvhdBrmrd9Lj9ahNAv2p6jUwRdJqbQI8WdQp2Z4eUmVtIwxzFqRxr78EuJah9ItIhQ/H28AVu/K4alv1/LH1kwAJn2/npv6RTM8rhXFpU6emb2On9amV6TVqXkw15/TliA/H/blF7NgQwZ/bs1k4T8G0SLUv07fAw0ASqmTrqTMibeX4F2tIK2tpB1ZZOQVM7hzM3y8D92RsWN/Ib9s3MuAjs1o07QhxhhW78rltfmbmLMmnRB/HyIaN2TL3nxKHE66RYTwjyGdefvXFH7dtI/ABt7ccG4Uc9bsISWjAIC2TRvSpUUITmOICgukV1QTPlqynV82ZlT83YhGATwxLIY9OQd46tt1hAT48OTwGKKaBvLGgs1M+n49z/2wHm8R/Hy8uHNQe3q2bkxuUSlvLNjCo1+trkjrrGZBjOsXdUzv05HI6bQiWEJCgtGpIJQ6NSxJ2c9fP07i7DaNuaJnBL2iGtM0yI9FW/Yxb/1ezu8YzsCO4YhUFvLT/tzBrOQ0lm3PAoHopoGIwL78ErpFhDDx4s6UOQyv/LwJP19vHrmkCy1C/THGsHlvPku2ZvJlUirLd2QD0C48kBFxEezOOUBGXglBft40DmxAx+bB7Msr5rX5mykucwIQ0yqEtOwDZBWWEuzvwzUJrTlQ6mBHZiFdWobQKtSf1+ZvYV9+Mf6+XjxwYUcSt2Xx49p0IhsH8NSIbhQUl/HJHzvYn1+CwbB1XwGlDoO/rxePXNKFITEtSNyexUtzN7IxPR+AQZ3CefHqOBoHNqh4H7buK+CbFWnkFZUyvn87moVU1uydTsO2/TbYBPr50Dzk+Gv9IrLMGJNQY3ttAoCIDAVeBryBd4wxk6q93hZ4DwgHMoGxxphUERkE/Ndt187AaGPMVyIyBRgA5LheG2eMST5cPjQAKHXsyr/r7gXy4axMzeZ/C1O4vEdL/tKleZWa9u6cA1z+6m/4entR5jRk5BUD0MDHi5IyJ14CTgP9O4Tx9IhutG0ayOeJO/n7jJV0bB7E+R3C8fISUjIKEIHQAF9+XLOH/OIynAYaNfSlqNSBr5cXfdo1JWlHFpkFJQBEhwVyU78owoL8KgraJoENaBbsR2GJg335xRS6+syHxrTgjoHt+WVjBr9v3kdU00C6RYYyPK4VIf6+Nc45p7CUj/7YzpCY5pzVLBiADXvyaNOkIQENvGvsX1hSRtL2bKLCGhLZuGHF9lKHk6mLtyPAuHOjanQZnWzHHABExBvYCFwIpAJLgTHGmLVu+3wOfGuM+UBELgBuMsZcXy2dJsBmINIYU+gKAN8aY2bU9iQ0AChPUeZw8v7v2xjQKZyOzYOPOR1jDGt35/J1chqzktMoLnNw47lRjOwZSUM/bzbsyWPq4m1sTM8nrnUjBnQMZ1hsK7IKS7js1d/YnVMEQHiwH+3DA2nVKICIRgH8sjGDzXvz+frOfrQLD2LZ9izWpOWwbV8BvaObMqBTOJ8t3clLczcC8MCFHXn2+/XEt23Mh7f0OWjXT1ZBCe/+thVfby9uOi+KzPwSHvt6Ndv3F9Irqgl92jWhb3RTWjcJqAhiTqehoKSMYLfC3Ok0pGYdoKCkjC4tQ475vTuTHE8AOAd4whgzxPX8IQBjzLNu+6wBhhpjdor9z+QYY0KqpTMBGGCMuc71fAoaAJSHySksZdbKNFqG+BMTEULL0ICD7vf416v5YPF2Any9ef6qHlzWoxUADtfFyd82ZZC0I5uiUgdB/j74eAlOA05jcDoN/r7ehAX5sTE9j0178/HxEgZ2CsdpYN76vVX+VuOGvsS3bUzyzhz25RfTK6ox3l5C0o5sZtx+DmnZRXy/eje7sg6Qln2APblFeHsJL4/uySXdWx72fHdmFjLhw2Ws251Ls2A/vrunP+HBfnXzZqpaO54AMApbuN/qen490McYc5fbPp8AfxhjXhaRkcAXQJgxZr/bPvOAF40x37qeTwHOAYqBn4GJxpjig/z9CcAEgDZt2sRv337QWU2VqlclZU7Ssg8QFRZ4yH027MljwoeJbN9fWLGtU/Ng/tK1GZ1ahNC6cQDB/j78snEfT327lmv7tGHDnjyWbc8irnUj4ts2Zv76vaTsK6BhA2/iWjciNMCX/OIyHE6Dlwgi4CXCAVdXSFiQH8PiWnFp95YVfdCb0vNI3J5FqcNJ44YNuLBrc/x9vTHG8EXSLp78Zg25RWVMGtmd0b3b1DiPMoeT4jIngX61G0NSWFLGWwu2cFFMC7pFhB7lO6vqwokOAK2A14BoYCFwJdDNGJPter0lsBJoZYwpddu2B2gATAa2GGOePFxetAWgTkVlDifjpyYyf0MGnVsEM6JnBIM7N6NxYAOmLt7OT2vTKXU4Sc0qJNjfl5evicPP14vlO7KZuy6dP7dmUn3o96BO4bxzYy8cTsPbv6bw87p0VqTm0LlFMH8deBYXxTTH9zCjX47H3twiVqflMKhTs1pfL1CnthPaBVRt/yBgvTEm0m3bvUCMMWbCIY4ZCPzNGHPZ4fKiAUDVlSUp+8kvKqN7ZGjFKItSh5Of16VTUOygW0Qo7cMDKy58FpU6WJyyn5/WppOWfYCWoQF0bB7E0G4t+N8vKUxZtI1r+7RhbVouyTvtCBURMAbOadeUJoENCAnw5b6/dKgxqqOwpIydmQdIzSqkwHXx8sIuzWtcdCx1OPHxEi2U1VE7VACoTRtuKdBBRKKBXcBo4NpqiYcBmcYYJ/AQdkSQuzGu7e7HtDTG7HZdMxgBrEapk+Dd37by1LcVYxgID/YjplUIa9Ny2ZtX2Qvp5+NFl5YhGGBtWg6lDkNgA2/aNg1kZWoO0/4s4d/f2HRuPS+aRy/rCkBa9gF+2ZhBalYhI8+OpH140GHz07CBD51aBNOpxeEv9p6oGr/yXEcMAMaYMhG5C5iDHQb6njFmjYg8CSQaY2YBA4FnRcRgu4DuLD9eRKKA1sAv1ZL+WETCAQGSgduP+2yUAvbkFLEyNZu41o1oFmLHkK/fk8eOzEKWbc9i8sIUhsa04Nb+0azalcOqXTms2ZVLTKsQnjsnisjGAaxOy2H1rlxW78rBADefF03f6Kac074p/r62Zr51XwHfrUyjsMTBgxd1qvj7rRoFMOYgfedKnWr0RjB1SssrKgXA39e7Sg14X34x36/eQ9L2LIbFtmJgp3DmrEnnPz9uYNNeewOOj5cwqHMztuzNJ2VfQcWxw+Na8cJVsVqjVh7jeLqAlDrpHE7Dk9+s4YPFdtSXn48XY/u25YqeEXy4eDszklJxOA0NG3gzc/kuIhoFsCv7AJ2aB/PopV2IaRXKz+vS+XpFGu3DAxl/fju6R4QSFuRX5/OpKHW60haAqhdFpQ4WbMhgX34xQ7u1ICyocmx4ZkEJ//xiJT+tTeeahNac1SyIdXty+Wr5LpwGGnh7cW2fNozu3Zp2YUF8unQHM5fv4pLuLRl3btRh54ZRyhMd11QQpwoNAKeXolIHTmNo2KCyoZlXVMqr8zYz7Y8d5BWXAbar5uw2jQlt6EtWQQlJO7IwwL8u68pN/aIrjt28N59fNmZwcbcWtGp08BuolFI1aReQOqlyDpRy1VuL2Jl5gEu6t6R7RAhpOUV8mbSL/QXFDIttxaj4SMKD/ZiZtIvE7VnszCzEz9ebuy7owMXdWtS4jf+sZkGc1ezwI2qUUrWnAUDViZIyJ4/PWg0Itw9oxyMzV5OSUcBlPVoyZ80evkhKpYG3F3FtGvHujQnEtm5UcexDl+h8LUrVBw0A6pgkbsvk7zNW0qZJQx66pDP/+XEjP61Np4G3F9P+3AHA86N6cFVCa4pKHeQWlRIW6FfvsyIqpSppAFBHJb/YzuvyxoLNtAwNIGl7FkNf+hWAfw+L4cKuzZm8MIXWTRpyVUJrwA7hLB87r5Q6dWgAUEeUW1TK6l05LEnJZOribWQXljLy7Aj+PSyGolInr8/fTNdWIVztKvCfGBZTvxlWStWKBgBVobCkjABfb0SEbfsKuPfTZDal51UsrgEwsFM4D1zYkR6Rtg8/2F8LfKVOVxoAPJwxhoWb9vGOaw3UQZ3CufHcKP4xYyWlDieje7WhWYgfnVsEExvZqMqydkqp05sGAA+WWVDCIzNX8f3qPTQP8eO6Pm34avku5m/IICzIj+kTzjniBGVKqdOXBgAP8d3K3Uz6YR0RjQI4q1kQGXnFJG7LIreolIkXd+bmftE08PHinsEd+GjJdkaeHUn0YRY3UUqd/jQAeIDfNu3jvk+X0y4siAMlDr5OTqNFiD8JUY25d3BHuraqHIffPMS/ysyWSqkzlwaAM9D+/GKmLt7OLxszCPD1ZmVqNu3Dg/j0tnMIDfA9cgJKKY+gAeAMsn1/Ae/8upXPEndSXOYkoW1jypxOekc3YdKVPbTwV0pVoQHgDLAqNYe3Fm7h+1W78fHy4oqeEYw/P5qzmukFXKXUodUqAIjIUOBl7Ipg7xhjJlV7vS12GchwIBMYa4xJdb3mAFa5dt1hjBnm2h4NTAeaAsuA640xJcd9Rh5i/vq9TF28jY3p+ezKPkCwnw8Tzm/PTf2iaqw5q5RSB3PEACAi3sDrwIVAKrBURGYZY9a67fYCMNUY84GIXAA8C1zveu2AMSbuIEk/B/zXGDNdRN4CbgHePI5z8RhfJ+/igc9W0DLUXsi9tXU0o+IjCfbXLh6lVO3VpgXQG9hsjEkBEJHpwHDAPQB0BR5wPZ4PfHW4BF0LwV9A5eLyHwBPoAHgsJxOw5RF23jqu7X0jmrCu+N6EeSnvXhKqWNTm6WTIoCdbs9TXdvcrQBGuh5fAQSLSFPXc38RSRSRJSIywrWtKZBtjCk7TJoAiMgE1/GJGRkZtcjumWlnZiHXv/cHT367lgs6NWPKTb218FdKHZe6KkH+BrwmIuOAhcAuoHwCmbbGmF0i0g6YJyKrgJzaJmyMmQxMBrsiWB3l97SRW1TKmwu28O5vW/H1Ev7fFd0Z07s1thGllFLHrjYBYBfQ2u15pGtbBWNMGq4WgIgEAVcaY7Jdr+1y/U4RkQVAT+ALoJGI+LhaATXSVJCRV8w1kxeTklHAyJ4RPDikExG6FKJSqo7UpgtoKdBBRKJFpAEwGpjlvoOIhIlIeVoPYUcEISKNRcSvfB+gH7DW2IWI5wOjXMfcCHx9vCdzJsksKGHsO3+wO7uIT8b34cVr4rTwV0rVqSO2AIwxZSJyFzAHOwz0PWPMGhF5Ekg0xswCBgLPiojBdgHd6Tq8C/A/EXFig80kt9FD/wSmi8jTwHLg3To8r9PWtn0FfPLnDr5M2kVuUSnvj+vFue3D6jtbSqkzkNjK+OkhISHBJCYm1nc2TpgfVu/h/k+TKXU4uaBzM24b0I74tk3qO1tKqdOciCwzxiRU367DSE4BTqfhjQWbeeHHjcS1bsRbY+NpEao3cyl1whkDOxZDZG/w9rzisDbXANQJlFlQws0fLOWFHzcyLLYV0yf01cJfqZNl26/w/sXw4yP1nZN64Xkh7xSyfk8ut0xJJCOvmKeGxzC2b9sza3hn8jQoK4KEm+o7JwdnDHx9J7TuDfHjju34Q/2/1s6CRa/C2TdAj2vApw5XUivYB34hNdMszAQvH/APOfhxR6s4D9KWQ1T/Q5/niVKUA04HNDzGLtCMDfDri9CyB7S/AJp1Ofh+676xv/94CyJ7QfdRB9+vPmTvhKSp4HDNkHPOXRAUXqd/QgNAPZm3Pp17piUT6OfNF3ecS/fI0PrOUt3KTIFZd4OzFHwbQuw1NfcpKbRf9JCWtU/3cIXukTgdMO8p6DAE2p4DqYmQ/DFsngtx14G321Qam3+2hV9YRxvEtv8OTTvAuXfZ1xc+D2u+gpu+r1ngbvsNvrgFvBvArLvgt//C+J8hoPGx5dtdcT68lmCDysXPVW7P3ArvXgSlB6DXLdD3rxDc/Nj/Tm4afHwVpK+G8/8BF5zEGnJZsT2X/Vug86Vw3n3QqufRpbH4dVg53f4gcN3n0OFCGyRXfW4Ds48/rJ8NHS6y7+usu6FlHISdVTO9kgL49Hpo2h4GTATjgLVfQ8tYW4Fwt+EHG4g7/KXaeZVAxnob1IKaV/28VZeWDJ9cDfl77ecIoOdYDQCnu+U7svjPjxv5bfM+urYM4d1xCbQMPQHDO/dtgmVTwFlmP2zn3n34D1x1TgcsecMWgGf9Bby8a74+42ZoP6iy9rx2Fvj4Qcch8NO/7Ae3VU/7xWrSDlr3qjx+4xz49gEo3A+jP4azBh8+P9k74ed/w4bv4dafoVlnG2Rm3Awj34awDkc+p0Wv2sJ49Rdw51Jb60MgP92m23WY3c9RBjNvh4K9lceK6/xjrrBf4EWv2uD1w0QY8UblcRu/h6/uhMbRcPMPsHUhfH4jLP+4MngcyLZ/sygH/EPBUQpL3rQFStwYuPBJ8D3EZ2LtV3AgC5I/gcGPQ4OGULAfPrrS1hTPugB+fxkWv2YLz/5/s7Vgd5kpsGMJBDSB0gLYvhjydtv/UXBLKMq2+S3KtsFy4f/Z1sZ5D9T8HByLPavgj/9B58ug09Car//+ii0ou42CLT/bYDxhftX/cUmBPY8m7ez7uPwjKMiAoc+BccL6b6HblXDhUzaQzbwdbpoNX46H3SugOBfOuhByU2HQw7aV8FJ3WPY+DHmmZp5+fMzmJWW+q2V7wH63xBsuesoGXBFY8SnMvM0eM+xVONs1JZqjFKZcAqlL7fOwjvZzXF55cJTZ93nlZ3bbvs32c/bXJfazfoJoADiJ1qblcvX/FhMa4Msjl3RhbN+2BDQ4whfqQJat9R5NU3j7Ipg22tYGfQPsFyR/L1w8qep+xsDOP20/aOxoCI2sfC1pKvz4qH0c2toWsm3PqXx9+Ye2MNr0o61BFWbC5+NszajjxbYgHPQoJNwM71wA06+1X+KQCJjzsA0u4Z1tAThtNFw9FTpdfIjzWQwfjqjM8+JXYfjrtjBPW24Lu8tfPvx7smc1zH8GWnS3BdDcx23+e0+whcWy9ysDQMp8W/iPfMfW+Lx9oUEgvBoPie9C07Pse9p+sG1BhHe2BfrqL2xB2jgaxn5h/2cxI+CPc+xxff8KG2bbgOAsq5o/H3/b1fLnZNuCuPYzaOS6/3LLPFszbdgEkj6EBsG2AFv7NXS/yr63ubvghq+hTV9bc058z+Zt+2K4Zzn4Bdn3LukD+H6iLcDK+QZCaIT9XzpKALHnPeZ7aB5jC7R5T8OSt6DLZXDe/dA4quZ7nLUdPrvBFs4Nm9r3Tbwg/kZbGOfvhe8eqOx22TAb7l5WtWW0f4ttXcVcAaPehZxU+N/5tvZ961x7Hk4HfHKN/dyC/RvGaR9HDwC/YFux6DrcntdV78PkgfBmP7tPi+7w28uQu9se23EoBDa1FZ3VX9qg4eV2eXTTXPv/O+cu6Hm9/dw1bAo9roKFL9jP84rptjWQ/DFE9wcvX9v6K8iwla95T9nCf/DjtpL046OVlYfMrfDlBEj90wYiLx/7/g597uhax8dAh4GeJMVlDoa/9jv7C0qYc9/5NAmsZZ/we0Ntf+b1M6FVtUlVjbEFgXjZD73TCcvegx8egkZtbSHUuK39wv/xJox4C5pE20I/Y4P9QO7bYNNqGGYL4ah+tjB/Nd4WbH1us7V5sLWRBg2hKBdePRuCWtjjY66wtbHMrTaQLH7dFvR3J9oAtHcdvHMhNImyhdySN6D3bbbmVFJga6+7V8CwV2wzd/8WWwPsfKn9u1Mug/2b4Zaf4PeXbHC69Wd4ZzAgtlb64HobTMqVFduCZuVn9j3KTLHv11+X2C/mhtn22HuSbK3tl0lwT7J9f2bcDFvmw4MbqvazT7/OBtfGbW2XwR2LbB72rLRf+PYX2MKuw5CqI0pWzbBdQiPfgTkP2fftvPtsfotyoLTQFkJBzWxhM+MmW/CO+w7WzLTHtoyzQW7yANtCWDbF1tbbDYL5T9u0e1xV9fOx809490IY+DAM+Ad8c68NAO0GwkVP2y4JLy9o3s0W1o6yylaJe/6dDvterptlu0yMA/reAYMesYVZ+T4fXA67V9rW3IFMuy0/3f7vugyzo22K82wAadsPpg6DXrfCJc/bNBylMHW4DdB3LYXgFnZ7ygL48ApbQI94yxbG85+B/g+CT4DNT7dR8PEoCGhkW50rpsPft9jPK9gW03d/g5H/s7XvN/raoNG2n20ZAKz8HL68FcbNtt8Dp9MG9R8mQmA4TFgAvtUGaDidsPRt2x24KxFa94Ex0+37+eV4G6QbtYXs7RB/E1z+kj1u3tM20PUcC6u+sPtf9t8Tdg3iUMNANQCcJM/9sJ43F2zhvXEJXNC5ln2zGRvg9d62RuAbaD+8rfu4LnD9B7b+YmtsXj62YC09ADuX2EJh1HuVrQZHqS1Edy6pTDuwmb0w1u1KWyP6cgJkbbXPy4rsF/62X6FFN9j6K3xwme0CGPwv+Okx2wUyfp7t9vnd9aG+YrLt609bDg2CqjbZN/4I066xX7pe4+2XvrwvvzjP1hy3zLNfyB2L7X5XvmsL5LcvsLWyfvfYpvFrCbawLMiw5/n5OFtb6nu7TS8t2dYQ8/dAaBsbeLx84Py/Q9tzbRpv9LFdANdOh5xd8FI3ex3goqfhP51sTe/SF6r+P7YutIUcwEXP2C6d3DQbSNsNrBqA3JUVw39jbGsObEHSovuh/+8rpttad6/x9nFQMxvA/ENswHxgPSR/BHOfsF0Q5bXlg/l0rA1mcdfa1kW/+2wt1OsYBwDmptnCK/lj24Vz1RRbeP3+iv1cDH8Del5Xub+jDH55Dn59wVYornwXmne1r333N1uY3/ozRJxtuwQT3638HLlb+o6tyPgF266pbqNg5OSq14OWfQDf3GO7HjtdbCs07hxllYFt1j02GA75f3CO677V4nx4/izbDTdgon3vUv+0NfuRb0P4EdbKdk8fbIVj04+2tu/jD7f8WNm15yi1lYfdK2yL+dIXqrbA65gGgHr03crd3DUtiavjW/PcqB5HPqDcT/+CRa/BrT/BjFtsAV2uYRj0uBpCWtlRIeu+sV+MC5+0BVn1C6X5e2Hpu7ZAb3MOBFa7u7gox36xV0y3Nebet8El/1f5+ld/hZWf2u6PjPUQey1c8aZtDbze2365r595+Au0Kz61BdmAf9YsgByl8O19sOZr6HWzrWnv22i/fGkr4P7Vlf2l08bYGnzXEXD1B/D2YJv/u5bawvijUbYwvvwlGwwPVtjtXAqN2lReKP3hIdsyadYV9q6FW+dBZHzVY4yBN8+1LZQH1x9dt9zPT9lCcMBEGPTQ4fc1xnYTrf3ansdtv9qWwNzHocvlcM1HkJcOL3ax13f+uujQF5j3bYLX+9hacs/rbb90XYzo+WMyfP9323LxbWg/fx2H2LwdLP2s7bZGX95iABsQX+tlu2siEmxh2+9e+xk+mPS1thVTnGe/E37VVrwrK4FX4mx32Kj3bGXmUPL32gB64ZNVvwuf32RbHA2b2GB3yQsQO+bYAybY/6dx1rx+kpduv0vR55/wUVaHCgAYY06bn/j4eHO6+X1Thunw8Gxzw+s/mgPFpbU/sKzUmOc7GPPJaPv8QI4xG34w5reXjVn6rjHFBVX3dzrtz/Eqzjdm/ffGlByouj1/nzEvxhjzv4HGLPvAmNKiytcKs4wpKzn+v22MMQ6H/b1vszFPtzDm8RBjfnq86j47/jTm2TbGpCXb58nT7H7/bmJ/vxxnTNaOo/u7Tqcx85+1x78Sf+j3cleSMWu/Obq0jbHv0aLXjSktrt3+BfuNmXqFMRvmVOZv+SfGZO+s3Gf9bGPS1x05rYX/MearO+1nqi79+l/7fv1fe2Nm3WvzfLSydxoz99/2sz79OmMcZUc+pvwzcjDLphrzny7GFOUefV6MMWbdt/acnokwZvviY0vjFISdtqdGmaotgBNo9qrd/P3zFVwQvJNXih9DOg6xTeCiHPj2Xtvd0feOygOMsRf0CvbZIWvzn4FrPrYX3jxR8jTbT3rT7Mr+4INxlNoLwUW5tqkdP+7Yh0Bu+sle4Is4+9iO9zRZ223XRV2MDjqeIb51pawEFvw/ewH5aIeensK0C+gkMsbwzHfreOe3rQxuVcbk4r/h7SixXTRdR9iLXJlb7M4DJsLAifaDv30xvO9qUpcW2m6eB9cf3fDNM82pUCgodZrTuYBOohnLUnnnt6081D2P8Tmv4JVfaIewrfvWjtgIaGxvIFr+kR19Ypz2RpvfX7Zjs+9KtBf5Gkd7duEPWvgrdQJpAKhjWQUlvDB7FTNCXiJh05+2QL/qAzviJryzHUnQopvrxqi+toBb+H+2xr/xexj4kB2T3O/e+j4VpdQZTgNAXcjYAL+9ROnAh5n0cxaxxYkkOP+0d2Ged7+9eQVsYV9+sxHYkQWXvQz5GbYP2yfADv1TSqmToFYBQESGAi9jF4R5xxgzqdrrbbGrgIUDmcBYY0yqiMQBbwIh2DWCnzHGfOo6ZgowgMr1gccZY5KP+4xOtvXf4fhiAt6l+UxZlsOnZdcxK2INFHUPDlIAACAASURBVDSyfftH6sLx9rF3Ks64xc4pEtj05ORbKeXxjhgARMQbeB24EEgFlorILFO5shfAC8BUY8wHInIB8CxwPVAI3GCM2SQirYBlIjLHuNYLBv5ujJlRlyd0Um1fDNOvZa2zHaW+7bjO53eaD3mc7nMX2fHate2/bxBob0hSSqmTqDZ3N/QGNhtjUowxJcB0YHi1fboC81yP55e/bozZaIzZ5HqcBuzFthLOCNk/Pcc+E8L/tXiRjlc8RMOybIbtegUpzrXDyJRS6hRWmwAQAex0e57q2uZuBTDS9fgKIFhEqvRliEhvoAGwxW3zMyKyUkT+W754fHUiMkFEEkUkMSMjoxbZPUnS19AodT6fel3C/27tT1DXIXb+m+SP7Fzt7QbWdw6VUuqw6mpFsL8BA0RkObZffxe2zx8AEWkJfAjcZEz5tH08BHQGegFNsIvE12CMmWyMSTDGJISHnzqNh7x5L1Jo/JCEW2jYwMfeCNNzrH2x08VVb3lXSqlTUG0uAu8CWrs9j3Rtq+Dq3hkJICJBwJXl/fwiEgJ8BzxijFnidsxu18NiEXkfG0RObau/hO8ehIZNabg/hQ+dF3HV+bGVr/e83s5U2fP6+sujUkrVUm0CwFKgg4hEYwv+0cC17juISBiQ6ardP4QdEYSINABmYi8Qz6h2TEtjzG6xayCOAFYf78mcUKnL7KIS4R0pCW7Din3e7Op6C+HBbjX9Rq3tnbtKKXUaOGIAMMaUichdwBzsMND3jDFrRORJ7ARDs4CBwLMiYoCFgGt+Va4Gzgeaisg417by4Z4fi0g4IEAycHvdnVYdKc6zszDm74U/37bzy1z/Fa/9vp9XVm1mzqC+9Z1DpZQ6ZjoX0OHMe8bepQsQEgnXfU5OcAfOe24e/TuG8cZ18Yc/XimlTgE6F9DRcjrtgtLR58O1n1esBPTuTxvJKy7jnsG1WINWKaVOYXU1CujMs3MJZO+AuLEVhX92YQnv/7aVi7u1oHOLkHrOoFJKHR8NAIeyYppdhtE1F392YQk3vr+UwlKH1v6VUmcE7QJyt2cVrPrcrnW65it7N2+DQLIKShjz9hJSMgp487qz6dJSa/9KqdOfBoByTocd5pm+2s7LDxA7GoAXf9rI5r35vH9TL/p3OHVuRlNKqeOhAaDc8o9s4X/ZS+Aosf3/Uf3ZmVnI9KU7uKZXay38lVJnFA0AYMf7z3vaLtASP67KKlSv/LwJEeGuC86qv/wppdQJoAEA4I//QcFeOyWzW+G/JSOfL5JSualfNC1DA+oxg0opVfd0FBDAulnQug9EVL2xa/IvKfh6e3H7gPb1lDGllDpxNADkpsHuFdBxaJXN+/KLmZm8i1HxkVXn+1FKqTOEBoBNP9rf1QLAR0u2U1Lm5ObzoushU0opdeJpANg4B0LbQLMuFZuKSh18uHg7gzs3o314UD1mTimlThzPDgClByBlAXQcUuXi76wVaewvKOGW/lr7V0qduTw7AGz7DUoLa3T/zFiWSrvwQM5p1/QQByql1OnPswPAhtng2xCizqvYtDOzkD+3ZnLl2ZGIW6tAKaXONJ4bAJxOWP8dnPWXitk+AWYu34UIjOhZfd17pZQ6s9QqAIjIUBHZICKbRWTiQV5vKyI/i8hKEVkgIpFur90oIptcPze6bY8XkVWuNF+Rk13dTl0K+enQZVjFJmMMXyalck67pkQ00hu/lFJntiMGABHxBl4HLga6AmNEpGu13V7ArvvbA3gSeNZ1bBPgcaAP0Bt4XEQau455ExgPdHD9DOVkWv8NePlCx4sqNiXtyGLb/kJGnh15mAOVUurMUJsWQG9gszEmxRhTAkwHhlfbpyswz/V4vtvrQ4CfjDGZxpgs4CdgqIi0BEKMMUuMXZNyKnZh+JPDGFj3DbQbCP6hFZu/SNpFgK83Q7u1OGlZUUqp+lKbABAB7HR7nura5m4FMNL1+AogWESaHubYCNfjw6UJgIhMEJFEEUnMyMioRXZrIX01ZG2rWOwF7Nj/b1ekMbRbC4L8dIokpdSZr64uAv8NGCAiy4EBwC7AURcJG2MmG2MSjDEJ4eF1NB3zum8BgU6XVmyat34vuUVljDxbL/4qpTxDbaq6u4DWbs8jXdsqGGPScLUARCQIuNIYky0iu4CB1Y5d4Do+str2KmmeUGnLoVlXCKoMKF8mpdI8xI9z24edtGwopVR9qk0LYCnQQUSiRaQBMBqY5b6DiISJSHlaDwHvuR7PAS4Skcaui78XAXOMMbuBXBHp6xr9cwPwdR2cT+1kboGmlTN87ssvZsGGDEb0jMDbS8f+K6U8wxEDgDGmDLgLW5ivAz4zxqwRkSdFpHwM5UBgg4hsBJoDz7iOzQSewgaRpcCTrm0AfwXeATYDW4Dv6+qkDstRZvv/3QLAtyvSKHMaRvbU0T9KKc9Rq6udxpjZwOxq2/7l9ngGMOMQx75HZYvAfXsi0O1oMlsncnaCswyaVAaA37fsJzoskE4tgk96dpRSqr543p3AmVvs7ybtAHvzV9L2LOLbNj7MQUopdebxvACwP8X+dnUBbd1XwP6CEhI0ACilPIznBYDMLeAbCEHNAVi2PQtAWwBKKY/jgQEgxXb/uKYeWrY9i9AAX134RSnlcTwvAOzfAk3bVTxNdPX/e+nwT6WUh/GsAOAog+ztFSOAsgtL2Lw3X7t/lFIeybMCQM4O1xBQ2wJI2qH9/0opz+VZAaDaCKDEbVn4eAmxkY3qMVNKKVU/PCsAVNwD4AoA27OIaRVCQAPvesyUUkrVD88KAPu3QIMgCGpGqcPJip3ZxLdtUt+5UkqpeuFZASB7BzRqCyKsSculuMyp/f9KKY/lWQEgbzeEtAQgcZudky4hSgOAUsozeVYAyE+HILvcY9KOLCIbB9A8xL+eM6WUUvXDcwKA0wH5eyG4OcYYErfpBHBKKc/mOQGgYB8YBwS3JDXrAHvzinUCOKWUR6tVABCRoSKyQUQ2i8jEg7zeRkTmi8hyEVkpIpe4tl8nIsluP04RiXO9tsCVZvlrzer21KrJ32N/BzV3mwBORwAppTzXEReEERFv4HXgQiAVWCois4wxa912exS7UtibItIVu3hMlDHmY+BjVzrdga+MMclux13nWhjmxMtLt7+DW5C0KYvABt66AIxSyqPVpgXQG9hsjEkxxpQA04Hh1fYxQIjrcSiQdpB0xriOrR95u+3v4BbsyCwkKixQ1/9VSnm02gSACGCn2/NU1zZ3TwBjRSQVW/u/+yDpXANMq7btfVf3z2OuxeFrEJEJIpIoIokZGRm1yO4h5LtaAEHN2ZNTRAsd/aOU8nB1dRF4DDDFGBMJXAJ8KCIVaYtIH6DQGLPa7ZjrjDHdgf6un+sPlrAxZrIxJsEYkxAeHn7sOczbAwGNwceP9NwimodqAFBKebbaBIBdQGu355Gube5uAT4DMMYsBvyBMLfXR1Ot9m+M2eX6nQd8gu1qOnHy9kBwS4pKHWQVltJSWwBKKQ9XmwCwFOggItEi0gBbmM+qts8OYDCAiHTBBoAM13Mv4Grc+v9FxEdEwlyPfYHLgNWcSPl7IKg5e3OLAbQFoJTyeEccBWSMKRORu4A5gDfwnjFmjYg8CSQaY2YBDwJvi8j92AvC44wxxpXE+cBOY0yKW7J+wBxX4e8NzAXerrOzOpi8dAjrxJ7cIgC9BqCU8nhHDAAAxpjZ2Iu77tv+5fZ4LdDvEMcuAPpW21YAxB9lXo+d02lbAMHNKwOAtgCUUh7OM+4EPpBpVwILakF6jg0AOgeQUsrTeUYAyHPdBRzcgt05RQT4ehPiX6vGj1JKnbE8LgCk5xbRItSfQ9x2oJRSHsMzAoDbPEB7cotoHuJXv/lRSqlTgGcEALcWwJ6cIlqGBtRvfpRS6hTgOQHAPxSntz9784r0ArBSSuEpASB/DwS1ILOwhFKHoYV2ASmlVO3uAzjtRfaC8M7sydF7AJRSqpxnBIB+9wKwZ62dEVS7gJRSylO6gFz0LmCllKrkUQEgPbcIL4HwIL0GoJRSHhUA9uQUERbkh4+3R522UkodlEeVhDkHSmncsEF9Z0MppU4JHhUASh1OGvh41CkrpdQheVRpWKIBQCmlKnhUaVhS5qSB9v8rpRRQywAgIkNFZIOIbBaRiQd5vY2IzBeR5SKyUkQucW2PEpEDIpLs+nnL7Zh4EVnlSvMVOQnTc5aUaQtAKaXKHbE0FBFv4HXgYqArMEZEulbb7VHgM2NMT+yawW+4vbbFGBPn+rndbfubwHigg+tn6LGfRu0Ulznx1RaAUkoBtWsB9AY2G2NSjDEl2MXdh1fbxwAhrsehQNrhEhSRlkCIMWaJa+3gqcCIo8r5MShxOPHTFoBSSgG1CwARwE6356mube6eAMaKSCp27eC73V6LdnUN/SIi/d3STD1CmgCIyAQRSRSRxIyMjFpk99C0C0gppSrVVWk4BphijIkELgE+FBEvYDfQxtU19ADwiYiEHCadGowxk40xCcaYhPDw8OPKpF4EVkqpSrWZDG4X0NrteaRrm7tbcPXhG2MWi4g/EGaM2QsUu7YvE5EtQEfX8ZFHSLPO6TBQpZSqVJvScCnQQUSiRaQB9iLvrGr77AAGA4hIF8AfyBCRcNdFZESkHfZib4oxZjeQKyJ9XaN/bgC+rpMzOoxS7QJSSqkKR2wBGGPKROQuYA7gDbxnjFkjIk8CicaYWcCDwNsicj/2gvA4Y4wRkfOBJ0WkFHACtxtjMl1J/xWYAgQA37t+TihtASilVKVarQdgjJmNvbjrvu1fbo/XAv0OctwXwBeHSDMR6HY0mT0eTqeh1GH0GoBSSrl4TGlY4nACaAtAKaVcPKY0rAgA2gJQSinAkwJAmbYAlFLKnceUhhoAlFKqKo8pDSsCgHYBKaUU4EkBQC8CK6VUFR5TGmoXkFJKVeUxpaG2AJRSqiqPKQ3LWwB+eg1AKaUADwwA2gJQSinLY0rD8gCgK4IppZTlMaWhXgNQSqmqPKY01C4gpZSqymNKQ70RTCmlqvKY0rC8C0gXhVdKKatWpaGIDBWRDSKyWUQmHuT1NiIy37X4+0oRucS1/UIRWSYiq1y/L3A7ZoErzWTXT7O6O62atAtIKaWqOuKCMK4lHV8HLgRSgaUiMsu1CEy5R4HPjDFvikhX7OIxUcA+4HJjTJqIdMOuKhbhdtx1roVhTji9CKyUUlXVpjTsDWw2xqQYY0qA6cDwavsYIMT1OBRIAzDGLDfGpLm2rwECRMTv+LN99PQagFJKVVWb0jAC2On2PJWqtXiAJ4CxIpKKrf3ffZB0rgSSjDHFbtved3X/POZaHP6EKSlz4iXgowFAKaWAursIPAaYYoyJBC4BPhSRirRFJAZ4DrjN7ZjrjDHdgf6un+sPlrCITBCRRBFJzMjIOOYM6oLwSilVVW1KxF1Aa7fnka5t7m4BPgMwxiwG/IEwABGJBGYCNxhjtpQfYIzZ5fqdB3yC7WqqwRgz2RiTYIxJCA8Pr805HVRJmVPvAlZKKTe1KRGXAh1EJFpEGgCjgVnV9tkBDAYQkS7YAJAhIo2A74CJxpjfy3cWER8RKQ8QvsBlwOrjPZnDKS5z6hBQpZRyc8QS0RhTBtyFHcGzDjvaZ42IPCkiw1y7PQiMF5EVwDRgnDHGuI47C/hXteGefsAcEVkJJGNbFG/X9cm5Kylz6gVgpZRyc8RhoADGmNnYi7vu2/7l9ngt0O8gxz0NPH2IZONrn83jV6rXAJRSqgqPKRFLyjQAKKWUO48pEXUUkFJKVeUxJaJeA1BKqao8pkTULiCllKrKY0rEYoeTBj7e9Z0NpZQ6ZXhMALBdQCd0tgmllDqteFAAcGgXkFJKufGYErHEoReBlVLKnceUiKVlRlsASinlxmNKRL0PQCmlqvKYEtFeBNZRQEopVa5WcwGdCfQ+AFWXSktLSU1NpaioqL6zolQFf39/IiMj8fX1rdX+HhEAjDHaBaTqVGpqKsHBwURFRXGCF7NTqlaMMezfv5/U1FSio6NrdYxHlIjlC8LregCqrhQVFdG0aVMt/NUpQ0Ro2rTpUbVKPaJELF8Q3ldvBFN1SAt/dao52s+kRwUAvQ9AKaUq1apEFJGhIrJBRDaLyMSDvN5GROaLyHIRWSkil7i99pDruA0iMqS2adal8i4gnQtInSn2799PXFwccXFxtGjRgoiIiIrnJSUlhz02MTGRe+6554h/49xzz62r7AJw3333ERERgdPprNN069u4ceOIjo4mLi6Ozp078+9///uY0lmwYAGLFi2q49wd3hEvAouIN/A6cCGQCiwVkVmuVcDKPYpdKvJNEemKXT0syvV4NBADtALmikhH1zFHSrPOlJYZAL0IrM4YTZs2JTk5GYAnnniCoKAg/va3v1W8XlZWho/Pwb/eCQkJJCQkHPFv1GVh5HQ6mTlzJq1bt+aXX35h0KBBdZa2u8Od94n0/PPPM2rUKIqKiujatSs33HBDrS/ElluwYAFBQUF1HngPpzbvVG9gszEmBUBEpgPDAffC2gAhrsehQJrr8XBgujGmGNgqIptd6VGLNOtMicMBaABQJ8a/v1nD2rTcOk2za6sQHr885qiOGTduHP7+/ixfvpx+/foxevRo7r33XoqKiggICOD999+nU6dOLFiwgBdeeIFvv/2WJ554gh07dpCSksKOHTu47777KloHQUFB5Ofns2DBAp544gnCwsJYvXo18fHxfPTRR4gIs2fP5oEHHiAwMJB+/fqRkpLCt99+WyNvCxYsICYmhmuuuYZp06ZVBID09HRuv/12UlJSAHjzzTc599xzmTp1Ki+88AIiQo8ePfjwww8ZN24cl112GaNGjaqRv8cee4zGjRuzfv16Nm7cyIgRI9i5cydFRUXce++9TJgwAYAffviBhx9+GIfDQVhYGD/99BOdOnVi0aJFhIeH43Q66dixI4sXLyY8PPyo/2/lF2ADAwMBWLZsGQ888AD5+fmEhYUxZcoUWrZsySuvvMJbb72Fj48PXbt2ZdKkSbz11lt4e3vz0Ucf8eqrr9K/f/+j/vtHqzYBIALY6fY8FehTbZ8ngB9F5G4gEPiL27FLqh0b4Xp8pDQBEJEJwASANm3a1CK7NRXrNQDlIVJTU1m0aBHe3t7k5uby66+/4uPjw9y5c3n44Yf54osvahyzfv165s+fT15eHp06deKOO+6oMY58+fLlrFmzhlatWtGvXz9+//13EhISuO2221i4cCHR0dGMGTPmkPmaNm0aY8aMYfjw4Tz88MOUlpbi6+vLPffcw4ABA5g5cyYOh4P8/HzWrFnD008/zaJFiwgLCyMzM/OI552UlMTq1asrat3vvfceTZo04cCBA/Tq1Ysrr7wSp9PJ+PHjK/KbmZmJl5cXY8eO5eOPP+a+++5j7ty5xMbGHnXh//e//52nn36azZs3c88999CsWTNKS0u5++67+frrrwkPD+fTTz/lkUce4b333mPSpEls3boVPz8/srOzadSoEbfffnuNltyJVldtpTHAFGPMf0TkHOBDEelWFwkbYyYDkwESEhLMsaRRfhFYh4GqE+Foa+on0lVXXYW36473nJwcbrzxRjZt2oSIUFpaetBjLr30Uvz8/PDz86NZs2akp6cTGRlZZZ/evXtXbIuLi2Pbtm0EBQXRrl27ikJ3zJgxTJ48uUb6JSUlzJ49mxdffJHg4GD69OnDnDlzuOyyy5g3bx5Tp04FwNvbm9DQUKZOncpVV11FWFgYAE2aNDnieffu3btKl8srr7zCzJkzAdi5cyebNm0iIyOD888/v2K/8nRvvvlmhg8fzn333cd7773HTTfddMS/V115F1B+fj6DBw9m0aJFhISEsHr1ai688EIAHA4HLVu2BKBHjx5cd911jBgxghEjRhz136srtQkAu4DWbs8jXdvc3QIMBTDGLBYRfyDsCMceKc06UzEKSAOAOsOVdz0APPbYYwwaNIiZM2eybds2Bg4ceNBj/Pz8Kh57e3tTVlZ2TPscypw5c8jOzqZ79+4AFBYWEhAQwGWXXVbrNAB8fHwqLiA7nc4qF7vdz3vBggXMnTuXxYsX07BhQwYOHHjYsfGtW7emefPmzJs3jz///JOPP/64xj5DhgwhPT2dhIQE3nnnnUOmFRQUxMCBA/ntt9+4+OKLiYmJYfHixTX2++6771i4cCHffPMNzzzzDKtWrarVe1DXalMiLgU6iEi0iDTAXtSdVW2fHcBgABHpAvgDGa79RouIn4hEAx2AP2uZZp2pHAWkAUB5jpycHCIibI/rlClT6jz9Tp06kZKSwrZt2wD49NNPD7rftGnTeOedd9i2bRvbtm1j69at/PTTTxQWFjJ48GDefPNNwNaQc3JyuOCCC/j888/Zv38/QEUXUFRUFMuWLQNg1qxZh2zR5OTk0LhxYxo2bMj69etZssT2Qvft25eFCxeydevWKukC3HrrrYwdO7ZKC8rdnDlzSE5OPmzhD/Yi9B9//EH79u3p1KkTGRkZFQGgtLSUNWvW4HQ62blzJ4MGDeK5554jJyeH/Px8goODycvLO2z6de2IJaIxpgy4C5gDrMOO9lkjIk+KyDDXbg8C40VkBTANGGesNcBn2Iu7PwB3GmMch0qzrk+uXOWNYBoAlOf4xz/+wUMPPUTPnj2PqsZeWwEBAbzxxhsMHTqU+Ph4goODCQ0NrbJPYWEhP/zwA5deemnFtsDAQM477zy++eYbXn75ZebPn0/37t2Jj49n7dq1xMTE8MgjjzBgwABiY2N54IEHABg/fjy//PILsbGxLF68uEqt393QoUMpKyujS5cuTJw4kb59+wIQHh7O5MmTGTlyJLGxsVxzzTUVxwwbNoz8/Pxj6v4Bew0gLi6OHj160L17d0aOHEmDBg2YMWMG//znP4mNjSUuLo5FixbhcDgYO3Ys3bt3p2fPntxzzz00atSIyy+/nJkzZxIXF8evv/56TPk4WmLMMXWr14uEhASTmJh41Md9v2o3d3ycxOx7+tO1VciRD1DqCNatW0eXLl3qOxv1Lj8/n6CgIIwx3HnnnXTo0IH777+/vrN11BITE7n//vtPWsF7Ih3ssykiy4wxNcb+ekSVWLuAlDox3n77beLi4oiJiSEnJ4fbbrutvrN01CZNmsSVV17Js88+W99ZOek8YjZQHQWk1Ilx//33n5Y1fncTJ05k4sQTOhnBKcsjSkRtASilVE0eUSLqZHBKKVWTR5SIeh+AUkrV5BElogYApZSqySNKxBKHExHw8dIFPNSZYdCgQcyZM6fKtpdeeok77rjjkMcMHDiQ8mHUl1xyCdnZ2TX2eeKJJ3jhhRcO+7e/+uor1q6tnLfxX//6F3Pnzj2a7B+WTht9eHU5bbRnBIAyJw28vXQFJ3XGGDNmDNOnT6+ybfr06YedkM3d7NmzadSo0TH97eoB4Mknn+Qvf/nLYY6overTRp8oJ+LGuNp4/vnnSU5OJjk5mQ8++KDiruSjoQHgKBW7AoBSJ8T3E+H9S+v25/vDD0scNWoU3333XcV8ONu2bSMtLY3+/ftzxx13kJCQQExMDI8//vhBj4+KimLfvn0APPPMM3Ts2JHzzjuPDRs2VOzz9ttv06tXL2JjY7nyyispLCxk0aJFzJo1q+LO1y1btjBu3DhmzJgBwM8//0zPnj3p3r07N998M8XFxRV/7/HHH+fss8+me/furF+//qD5Kp82+o477mDatGkV29PT07niiiuIjY0lNja2ogCcOnUqPXr0IDY2luuvvx6gSn7Azs9Tnnb//v0ZNmwYXbt2BWDEiBHEx8cTExNTZSK7H374gbPPPpvY2FgGDx6M0+mkQ4cOZGRkADZQnXXWWRXPj9bBpo0eMGAA8fHxDBkyhN27dwN2UruuXbvSo0cPRo8ezbZt23jrrbf473//Wyd3DHtEqVjicGr/vzqjNGnShN69e/P9998DtvZ/9dVXIyI888wzJCYmsnLlSn755RdWrlx5yHSWLVvG9OnTSU5OZvbs2SxdurTitZEjR7J06VJWrFhBly5dePfddzn33HMZNmxYRU22ffv2FfsXFRUxbtw4Pv30U1atWkVZWVnFPD8AYWFhJCUlcccddxyym6l82ugrrriC7777rmK+n/Jpo1esWEFSUhIxMTEV00bPmzePFStW8PLLLx/xfUtKSuLll19m48aNgJ02etmyZSQmJvLKK6+wf/9+MjIyGD9+PF988QUrVqzg888/rzJtNHBc00bHxcURGRnJ6NGjq0wbPWPGDJYtW8bNN9/MI488Atib1JYvX87KlSt56623iIqK4vbbb+f+++8nOTn5uNcM8IgbwUrLNACoE+jiSfXyZ8u7gYYPH8706dN59913Afjss8+YPHkyZWVl7N69m7Vr19KjR4+DpvHrr79yxRVX0LBhQ8DOiVNu9erVPProo2RnZ5Ofn8+QIUMOmka5DRs2EB0dTceOdtG/G2+8kddff5377rsPsAEFID4+ni+//LLG8Tpt9MmfNtojAoC2ANSZaPjw4dx///0kJSVRWFhIfHw8W7du5YUXXmDp0qU0btyYcePGHXYq5MMZN24cX331FbGxsUyZMoUFCxYcV37Lp5Q+1HTSOm30yZ822iNKxRK9BqDOQEFBQQwaNIibb7654uJvbm4ugYGBhIaGkp6eXtFFdCjnn38+X331FQcOHCAvL49vvvmm4rW8vDxatmxJaWlplcLuUNMWd+rUiW3btrF582YAPvzwQwYMGFDr89Fpo0/+tNEeUSqWaBeQOkONGTOGFStWVASA2NhYevbsSefOnbn22mvp16/fYY8/++yzueaaa4iNjeXiiy+mV69eFa899dRT9OnTh379+tG5c+eK7aNHj+b555+nZ8+ebNmypWK7v78/77//PldddRXdu3fHy8uL22+/vVbnodNG18+00R4xHfTr8zeTV1TGPe4OVwAABupJREFUxIs7H3lnpWpBp4P2TKfDtNFHMx20R1wDuHPQWfWdBaXUaW7SpEm8+eabB+37P13Vql9ERIaKyAYR2SwiNQYoi8h/RSTZ9bNRRLJd2we5bU8Wkf/f3vnGyFWVYfz3pJROwMS2VLF2WrpqA6mobdNoG/vB4B+oIYCJMduQiJGkXwSREHWXJiSS+MFo/Jcg2iiQmEaMK+imCSpCPxeKQimUSrWtbNPaslFMICLVxw/nLL2dnWVncXbP3Zn3l9x0zjl3Js8+03Pfuefcc95/Sbout90n6UilbV13/7QgCILuMTQ0xLFjx9iyZUtpKV1j2jsASQuAu4CPA2PA45JGbb++FND2rZXzbwbW5/o9wLpcvxQ4DPyu8vFftj1CEMxDbMfq8qBWzHRIv5M7gA8Ch23/xfa/gfuBa9/g/G2kvMCtfBp4yPYrM1IYBDWk0WgwPj4+4w4XBLOFbcbHx2k0Gh2/p5M5gBXAC5XyGPChdidKugQYAB5t0zwIfLul7uuS7gAeAYZsv9rmM7cD2wFWrVrVgdwgmH2azSZjY2NveiuAIJgNGo0GzWaz4/O7PQk8CIzY/k+1UtJy4H1AdfvCYeAkcD6wE/gqcGfrB9remdvZuHFj/NwKasHChQvPWVEaBPORToaAjgMrK+VmrmvHIO2Hfz4DPGj79RUZtk848SpwL2moKQiCIJgjOgkAjwNrJA1IOp90kR9tPUnSZcASYPJ65jbzAvmuAKVZtOuAAzOTHgRBEPw/TDsEZPuMpJtIwzcLgHtsPyPpTmCf7YlgMAjc75ZZMUmrSXcQrZt775L0NkDAk0BnSwaDIAiCrjCvVgJLOg0cm+HblgEvzoKcbhIau0PdNdZdH4TGblE3jZfYnrR39bwKAG8GSfvaLYGuE6GxO9RdY931QWjsFvNBI/TJZnBBEATBZCIABEEQ9Cn9EAB2Tn9KcUJjd6i7xrrrg9DYLeaDxt6fAwiCIAja0w93AEEQBEEbIgAEQRD0KT0dAKbLY1BAz0pJeyQ9K+kZSbfk+qWSHpb0fP53SQ20LpD0R0m7c3lA0t7s5c/zqvCS+hZLGpH0nKSDkjbXzUdJt+bv+YCkn0lqlPZR0j2STkk6UKlr65sS389a90vaUFDjN/N3vV/Sg5IWV9qGs8ZDkq4spbHSdpskS1qWy0V87ISeDQCVPAZbgbXANklry6riDHCb7bXAJuALWdMQ8IjtNeSdUQtqnOAW4GCl/A3gO7bfA/wduLGIqrN8D/iN7cuAD5C01sZHSSuALwIbbV9OWkU/SHkf7wOuaqmbyretwJp8bAfuLqjxYeBy2+8H/kTaTJLcfwaB9+b3/CD3/RIakbQS+ATw10p1KR+nx3ZPHsBm4LeV8jAwXFpXi8ZfkxLtHAKW57rlwKHCupqkC8EVwG7Sdh0vAue187aAvrcCR8gPMVTqa+MjZ7dRX0racmU3cGUdfARWAwem8w34EbCt3XlzrbGl7VPArvz6nH5N2rJmcymNwAjpB8lRYFlpH6c7evYOgPZ5DFYU0jKJvEfSemAvcLHtE7npJHBxIVkTfBf4CvDfXL4I+IftM7lc2ssB4DRwbx6m+rGkC6mRj7aPA98i/RI8AbwEPEG9fJxgKt/q2oc+DzyUX9dGo6RrgeO2n2ppqo3GVno5ANQWSW8Bfgl8yfY/q21OPxGKPZsr6WrglO0nSmnogPOADcDdttcDL9My3FMDH5eQMucNAO8ELqTNkEHdKO3bdEjaQRpKrVVmdkkXALcDd5TWMhN6OQDMJI/BnCFpIeniv8v2A7n6b5XtsZcDp0rpAz4MXCPpKCn95xWk8fbFkiZ2jy3t5RgwZntvLo+QAkKdfPwYcMT2aac8GA+QvK2TjxNM5Vut+pCkzwFXA9fnQAX10fhuUrB/KvedJvAHSe+gPhon0csBoKM8BnOJJAE/AQ7arqbHHAVuyK9vIM0NFMH2sO2m7dUkzx61fT2wh5TXGcprPAm8IOnSXPVR4Flq5CNp6GeTpAvy9z6hsTY+VpjKt1Hgs/kplk3AS5WhojlF0lWkYclrfG5e8VFgUNIiSQOkidbH5lqf7adtv9326tx3xoAN+f9qbXycROlJiNk8gE+Snhj4M7CjBnq2kG6v95NyIDyZNV5EmnR9Hvg9sLS01qz3I8Du/PpdpI51GPgFsKiwtnXAvuzlr0jJiGrlI/A14DlSsqOfAotK+0hKzHQCeI10kbpxKt9Ik/935f7zNOmJplIaD5PG0Sf6zQ8r5+/IGg8BW0tpbGk/ytlJ4CI+dnLEVhBBEAR9Si8PAQVBEARvQASAIAiCPiUCQBAEQZ8SASAIgqBPiQAQBEHQp0QACIIg6FMiAARBEPQp/wPkHyy1ewKBzwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Test Section"
      ],
      "metadata": {
        "id": "DFFCgjnAl7SK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# This is what is known as a Tensorflow (Keras) Sequential model\n",
        "# We will talk at some level about each of these layer types in class.\n",
        "#\n",
        "\n",
        "###Test####\n",
        "\n",
        "model_1 = Sequential()\n",
        "model_1.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 #kernel_initializer='he_normal',\n",
        "                 input_shape=input_shape))\n",
        "model_1.add(Dropout(0.7))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Conv2D(64, kernel_size=(3,3)))\n",
        "model_1.add(LeakyReLU(alpha=0.05))\n",
        "model_1.add(Dropout(0.7))\n",
        "model_1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(800))  \n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Dropout(0.7))\n",
        "model_1.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "my_callbacks_1 = [ModelCheckpoint('model_out.hdf5', monitor='val_accuracy',  mode='max', save_best_only=True, period=1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GClnAAG4mvpF",
        "outputId": "3d24dd04-c599-436e-b8c6-cacdc75d875b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flag to determine whether we use Keras' Image augmentation data generator\n",
        "augmentation = False\n",
        "\n",
        "#\n",
        "# Compile the model so we can fit it. Researching loss functions and optimizers\n",
        "# might be a good thing to do.\n",
        "#\n",
        "model_1.compile(loss=keras.losses.categorical_crossentropy, \n",
        "              optimizer=keras.optimizers.Adam(), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "if not augmentation:\n",
        "    #\n",
        "    # Fit the model.  Once the model is trained we'll evaluate the performance.\n",
        "    print('not using image augmentation')\n",
        "    hist1 = model_1.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=my_callbacks_1)\n",
        "else:\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "    hist1 = model_1.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                           steps_per_epoch=len(x_train) / batch_size, validation_data=(x_test, y_test),\n",
        "                           epochs=epochs, verbose=1, callbacks=my_callbacks_1, workers = 2)\n",
        "\n",
        "\n",
        "score_1 = model_1.evaluate(x_test, y_test)\n",
        "\n",
        "#\n",
        "# Predict on the test data and pass to metrics function\n",
        "yhat = np.argmax(model_1.predict(x_test), axis=-1)\n",
        "y_dec = decode_one_hot(y_test)\n",
        "\n",
        "print(\"\\nSUBMIT THIS BLOCK for the Competition\\n\")\n",
        "print(metrics.classification_report(y_dec, yhat))\n",
        "print(\"Testing Loss:\", score_1[0])\n",
        "print(\"Testing Accuracy:\", score_1[1])\n",
        "print(\"END SUBMISSION BLOCK\\n\")\n",
        "\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysjXCUMTmAro",
        "outputId": "5bde7417-bfb4-4a2c-def8-425d895df36d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not using image augmentation\n",
            "Epoch 1/150\n",
            "270/270 [==============================] - 6s 19ms/step - loss: 0.7502 - accuracy: 0.7299 - val_loss: 0.6407 - val_accuracy: 0.8373\n",
            "Epoch 2/150\n",
            " 17/270 [>.............................] - ETA: 4s - loss: 0.5067 - accuracy: 0.8094"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_list_1 = list(range(1, len(hist1.history['accuracy']) + 1))\n",
        "plt.plot(epoch_list_1, hist1.history['accuracy'], epoch_list_1, hist1.history['val_accuracy'])\n",
        "plt.legend((\"Training Accuracy - Test\", \"Validation Accuracy - Test\"))\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epoch_list_1, hist1.history['loss'], epoch_list_1, hist1.history['val_loss'])\n",
        "plt.legend((\"Training Loss - Test\", \"Validation Loss - Test\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1RMJEJXEmQ5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare\n",
        "\n",
        "plt.plot(epoch_list, hist.history['accuracy'], epoch_list, hist.history['val_accuracy'])\n",
        "plt.plot(epoch_list_1, hist1.history['accuracy'], epoch_list_1, hist1.history['val_accuracy'])\n",
        "plt.legend((\"Training Accuracy - Best\", \"Validation Accuracy - Best\", \"Training Accuracy - Test\", \"Validation Accuracy - Test\"))\n",
        "plt.show()\n",
        "\n",
        "#plt.plot(epoch_list_1, hist1.history['loss'], epoch_list_1, hist1.history['val_loss'])\n",
        "#plt.legend((\"Training Loss - Test\", \"Validation Loss - Test\"))\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "print(\"Testing Accuracy - Best:\", score[1])\n",
        "print(\"Testing Accuracy - Test:\", score_1[1])"
      ],
      "metadata": {
        "id": "Btx6l1w8nnN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-imOV3gbDji"
      },
      "source": [
        "## Visualization of Performance on the Test Set\n",
        "\n",
        "Here is a visualization of how well our classifier can do inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfsF8TlLwarT"
      },
      "source": [
        "import cv2\n",
        "from imutils import build_montages\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# initialize our list of output images\n",
        "images = []\n",
        "\n",
        "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
        "\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]\n",
        " \n",
        "# randomly select a few testing fashion items\n",
        "for i in np.random.choice(np.arange(0, len(y_test)), size=(16,)):\n",
        "\t# classify the clothing\n",
        "\tprobs = model.predict(x_test[np.newaxis, i])\n",
        "\tprediction = probs.argmax(axis=1)\n",
        "\tlabel = labelNames[prediction[0]]\n",
        " \n",
        "\t# extract the image from the testData if using \"channels_first\"\n",
        "\t# ordering\n",
        "\tif K.image_data_format() == \"channels_first\":\n",
        "\t\timage = (x_test[i][0] * 255).astype(\"uint8\")\n",
        " \n",
        "\t# otherwise we are using \"channels_last\" ordering\n",
        "\telse:\n",
        "\t\timage = (x_test[i] * 255).astype(\"uint8\")\n",
        "    # initialize the text label color as green (correct)\n",
        "\tcolor = (0, 255, 0)\n",
        " \n",
        "\t# otherwise, the class label prediction is incorrect\n",
        "\tif prediction[0] != np.argmax(y_test[i]):\n",
        "\t\tcolor = (0, 0, 255)\n",
        " \n",
        "\t# merge the channels into one image and resize the image from\n",
        "\t# 28x28 to 96x96 so we can better see it and then draw the\n",
        "\t# predicted label on the image\n",
        "\timage = cv2.merge([image] * 3)\n",
        "\timage = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
        "\tcv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
        "\t\tcolor, 2)\n",
        " \n",
        "\t# add the image to our list of output images\n",
        "\timages.append(image)\n",
        "# construct the montage for the images\n",
        "montage = build_montages(images, (96, 96), (4, 4))[0]\n",
        " \n",
        "# show the output montage\n",
        "cv2_imshow( montage)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMDjuN_anxKM"
      },
      "source": [
        "\n",
        "#Need to check 50/200\n",
        "#epochs = 50                 # Number of Training Epochs\n",
        "#num_classes = 10            # This is the number of classes in the Fashion MNIST dataset\n",
        "#batch_size = 200          # This parameter can be adjusted\n",
        "#img_rows, img_cols = 28, 28 # Pixel sizes of the Images in the Dataset\n",
        "\n",
        "#Current Best\n",
        "epochs = 40                 # Number of Training Epochs\n",
        "num_classes = 10            # This is the number of classes in the Fashion MNIST dataset\n",
        "batch_size = 300          # This parameter can be adjusted\n",
        "img_rows, img_cols = 28, 28 # Pixel sizes of the Images in the Dataset\n",
        "\n",
        "#\n",
        "# This is what is known as a Tensorflow (Keras) Sequential model\n",
        "# We will talk at some level about each of these layer types in class.\n",
        "#\n",
        "\n",
        "###Test####\n",
        "\n",
        "model_1 = Sequential()\n",
        "model_1.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 #kernel_initializer='he_normal',\n",
        "                 input_shape=input_shape))\n",
        "model_1.add(Dropout(0.7))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Conv2D(64, kernel_size=(3,3)))\n",
        "model_1.add(LeakyReLU(alpha=0.05))\n",
        "model_1.add(Dropout(0.6))\n",
        "model_1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(1000))  \n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "my_callbacks = [ModelCheckpoint('model_out.hdf5', monitor='acc', save_best_only=True, period=1)]\n",
        "\n",
        "\n",
        "#Testing Accuracy - Test: 0.9271717071533203"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}